---
title: "Mengumpulkan Review Konsumen Tidak Pernah Semudah Ini!"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/ikanx101/_posts/home tester club")
library(dplyr)
library(ggplot2)
library(EBImage)
```

Di dunia _market research_, data terkait konsumen bisa dibagi menjadi dua:

1. Data persepsi.
1. Data habit.

---

## Data Persepsi

Persepsi (dari bahasa Latin: _perceptio_ atau _percipio_) adalah tindakan menyusun, mengenali, dan menafsirkan informasi sensoris guna memberikan gambaran dan pemahaman tentang lingkungan.

Data persepsi merupakan data yang berasal dari pemahaman, ide, atau pendapat pribadi dari konsumen.

Untuk mendapatkan data ini, cara terbaik yang bisa dilakukan adalah dengan cara survey (DITANYAKAN langsung kepada responden).

---

## Data Habit

Habit atau kebiasaan adalah suatu hal yang lazim, umum, dan yang biasa dilakukan. Menurut Peter Cape (2013):

> _When you ask people randomly throughout the day what they are doing (behavior), 30% of the time there will be a mismatch between what they are doing and what they are thinking about._

Oleh karena itu, cara terbaik untuk mendapatkan data ini adalah dengan memanfaatkan sumber data lain seperti jejak digital, data transaksi, dan lainnya.

Data seperti ini sebaiknya tidak ditanyakan langsung. Jika terpaksa ditanyakan langsung, sebaiknya ada metode untuk melakukan validasi atas jawaban tersebut.

---

Sebagai _market researcher_, saya tahu betul bagaimana sulitnya mencari data persepsi. Berdasarkan pengalaman saya selama ini, saya sangat percaya bahwa metode seperti _face-to-face_ interview adalah cara terbaik untuk mendapatkan data persepsi konsumen. Namun biasanya ada tiga hal yang membuat F2F interview menjadi sulit dilakukan:

1. Waktu yang mepet.
1. Biaya yang terbatas.
1. Kekurangan tenaga (_man power_).

Di zaman transformasi digital seperti sekarang ini, kadang kita hanya butuh duduk sejenak dan mencari apa yang kita mau di internet. Sama seperti mencari data persepsi konsumen.

> Jika dulu saya harus mencari konsumen untuk dijadikan responden. Kini responden sendiri yang __"datang"__ memberikan data persepsinya.

_Lho, gimana maksudnya?_

---

Beberapa waktu lalu, seorang rekan kerja saya menginformasikan mengenai keberadaan situs yang menampung _review_ konsumen bernama [_Home Tester Club Indonesia_](https://www.hometesterclub.com/id/id/).

```{r,echo=FALSE}
plot1 = readImage("skrin.jpg")
plot(plot1)
```

---

## Situs Home Tester Club Indonesia

Berdasarkan informasi di situsnya:

> _Home Tester Club_ adalah komunitas para pembeli yang menguji dan membagikan _review_ produk untuk membantu pembeli lainnya berbelanja lebih baik. _Home Tester Club_ adalah rumahnya ribuan _review_ produk. Dengan bergabung di sini kamu akan mendapat kesempatan menguji coba produk gratis dan produknya akan diantar langsung ke rumah kamu.

Namun demikian, tidak semua _member_ mendapatkan produk gratis untuk diuji. Beberapa _member_ masih bisa memberikan _review_ berdasarkan pengalaman pribadi mereka menggunakan produk yang mereka beli dengan uang pribadi.

Jika kita asumsikan semua _member_ memberikan _review_ yang jujur, maka data _review_ ini sangat kaya akan informasi.

---

## Bagaimana cara saya mengeksplorasi data ini?

Sebelum berbicara lebih jauh mengenai cara saya mengeksplorasi, pertanyaan paling mendasar yang harus saya jawab adalah:

> __Bagaimana cara saya mengambil semua data yang ada di situs tersebut?__

Pertanyaan di atas adalah pertanyaan __paling standar__ yang biasa dihadapi oleh semua orang di zaman sekarang. _hehe_

---

## _Webscraping_ __Home Tester Club__

Seperti biasa, saya menggunakan __R__ untuk membuat beberapa baris algoritma yang bertugas untuk mendapatkan data yang saya mau.

Dari situs tersebut, ada beberapa data yang bisa saya ambil, yakni:

1. Nama produk.
1. Deskripsi produk.
1. _Rating_ produk.
1. Berapa banyak _reviewers_.
1. Isi komentar atau _review_.

Berikut adalah _functions_ algoritma yang saya buat:

```{r}
scrape_func = function(url){
  data = read_html(url) %>% {tibble(
      merek = html_nodes(.,"#htc-breadcrumb .active") %>% html_text(),
      rate = html_nodes(.,".pp-ratereview-counter li") %>% html_text() %>% paste(collapse = " "),
      deskripsi = (html_nodes(.,".text-left") %>% html_text())[[1]]
  )}
  return(data)
}
```

Cukup gunakan _function_ tersebut ke _links_ masing-masing produk di situs tersebut. 

Sebagai _showcase_, saya akan mengambil `384` produk yang ada di kategori [__Dapur Makanan__](https://www.hometesterclub.com/id/id/reviews/category-food-pantry). _Links_ `384` produk itu tersedia di [sini](https://raw.githubusercontent.com/ikanx101/belajaR/master/Bukan%20Infografis/Home%20Tester%20Club/Scraping%20Bahan/links.txt).

Data saya _scrape_ pada tanggal `1 Desember 2020 pukul 14âˆ¶34âˆ¶57 WIB`.

---

## _Showcase_: Semua Produk di Kategori __Dapur Makanan__

Setelah saya bersihkan data hasil _scrape_, saya dapatkan data berupa tabel seperti di bawah ini:

```{r,echo=FALSE}
rm(list=ls())
print("Contoh 10 data teratas hasil scrape")
load("~/Documents/belajaR/Bukan Infografis/Home Tester Club/Scraping Bahan/data dapur makanan.rda")
head(clean_data,10)
```

Mari kita cek beberapa analisa sederhana berikut ini:

---

### _Top Reviewed Product_

Dari `384` produk yang ada di kategori __dapur makanan__, ada beberapa produk yang paling banyak di-_review_ oleh _member_. Mari kita lihat __Top 20__ produk yang paling banyak di-_review_.

```{r,fig.retina=10,echo=FALSE}
clean_data %>% 
  arrange(desc(review_no)) %>% 
  head(20) %>% 
  mutate(warna = ifelse(grepl("tropicana",merek,ignore.case = T),
                        1,
                        0),
         merek = stringr::str_to_title(merek)
         ) %>% 
  ggplot(aes(x = reorder(merek,review_no),
             y = review_no)) +
  geom_col(aes(fill = factor(warna)),
           color = "black") +
  geom_label(aes(label = review_no),
             size = 2) +
  labs(title = "Produk apa saja yang paling banyak\ndi-review oleh member?",
        subtitle = "Top 20 produk yang mendapatkan review terbanyak",
        caption = "Scraped and Visualized\nusing R\nikanx101.com") +
  coord_flip() +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text.x = element_blank(),
        legend.position = "none")
```

Sekarang kebalikannya, kita cek 20 produk terbawah yang paling sedikit di-_review_ oleh _member_:

```{r,fig.retina=10,echo=FALSE}
clean_data %>% 
  arrange(review_no) %>% 
  head(20) %>% 
  mutate(warna = ifelse(grepl("tropicana",merek,ignore.case = T),
                        1,
                        0),
         merek = stringr::str_to_title(merek)
         ) %>% 
  ggplot(aes(x = reorder(merek,-review_no),
             y = review_no)) +
  geom_col(aes(fill = factor(warna)),
           color = "black") +
  geom_label(aes(label = review_no),
             size = 2) +
  labs(title = "Produk apa saja yang paling sedikit\ndi-review oleh member?",
        subtitle = "Bottom 20 produk yang mendapatkan review tersedikit",
        caption = "Scraped and Visualized\nusing R\nikanx101.com") +
  coord_flip() +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text.x = element_blank(),
        legend.position = "none")
```


### Sebaran Banyaknya _Reviews_

Kalau kita lihat sebaran data banyaknya _reviews_, saya dapatkan informasi berikut:

```{r,fig.retina=10,echo=FALSE}
nfi = 
  clean_data %>% 
  filter(grepl("tropicana|nutrisari|wrp|lmen|hilo|hi lo|orang",merek,ignore.case = T))
produk_nfi = nfi$review_no

clean_data %>% 
  ggplot(aes(x = review_no)) +
  geom_density(color = "darkred",
               fill = "darkred",
               alpha = .4) +
  geom_vline(xintercept = produk_nfi,
             color = "darkgreen") +
  annotate(x = 1450,
           y = .002,
           "label",
           label = "Tropicana Slim\nBeras Merah: 866 reviews",
           color = "darkgreen",
           size = 3) +
  annotate(x = 1100,
           y = .0035,
           "label",
           label = "TS Kecap Manis: 56 reviews\nTS Stevia: 76 reviews\nWRP Fruitbar Apricot Raisin: 113 reviews\nTS Alergon Cookis: 113 reviews\nWRP Active Body Shape: 116 reviews\nTS SWT Green Tea: 136 reviews",
           color = "darkgreen",
           size = 3) +
  theme_minimal() +
  labs(x = "Banyaknya reviews",
       subtitle = "Density plot dari banyaknya reviews",
       title = "Sebaran banyaknya reviews yang diberikan oleh member di\nkategori dapur makanan",
       caption = "Scraped and Visualized\nusing R\nikanx101.com") +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank())
```

Dari graifk sebaran di atas, kita bisa melihat ada ketidakmerataan banyaknya _reviews_ yang diberikan oleh _member_. Sebagian kecil produk mendapatkan lebih dari `1000` _reviews_. Mayoritas dari produk mendapatkan _reviews_ sebanyak `r median(clean_data$review_no)` (nilai tengah - median - dari data _review_).

Kita bisa melihat bahwa beberapa produk Nutrifood mendapatkan _reviews_ di kisaran angka tersebut kecuali produk __Tropicana Slim Beras Merah__ yang mendapatkan _reviews_ yang cukup banyak sehingga masuk __Top 20 Reviewed Products__.

### _Top Rating Product_

_Member_ bisa memberikan _rating_ kepada produk yang pernah dikonsumsinya menggunakan skala `1-5`. Produk apa saja yang mendapatkan _rating_ terbaik?

```{r,fig.retina=3,fig.height=9,echo=FALSE}
clean_data %>% 
  arrange(desc(rate_no)) %>% 
  head(59) %>% 
  mutate(warna = ifelse(grepl(paste(nfi$merek,collapse = "|"),merek,ignore.case = T),
                        1,
                        0
                        )
         ) %>% 
  ggplot(aes(x = reorder(merek,rate_no),
             y = rate_no)) +
  geom_col(aes(fill = factor(warna))) +
  geom_label(aes(label = rate_no),
             size = 2) +
  coord_flip() +
  labs(title = "Top 59 Produk dengan Rata-Rata Rating Terbaik",
       subtitle = "Dari 384 produk di kategori dapur makanan",
       caption = "Scraped and Visualized\nusing R\nikanx101.com") +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text.x = element_blank(),
        legend.position = "none")
```
Mungkin kalian bertanya-tanya, kenapa `59` produk yang ditampilkan?

Karena produk urutan ke `60` memiliki nilai yang sama dengan produk urutan ke `61` sampai produk urutan ke `116`. 

### Sebaran _Rating_ Produk

Mari kita lihat bersama bagaimana sebaran dari _rating_ yang diberikan oleh _member_:

```{r,fig.retina=10,echo=FALSE}
produk_nfi = unique(nfi$rate_no)

clean_data %>% 
  ggplot(aes(x = rate_no)) +
  geom_density(color = "darkred",
               fill = "darkred",
               alpha = .4) +
  geom_vline(xintercept = produk_nfi,
             color = "darkgreen") +
  annotate(x = 3.5,
           y = 1,
           "label",
           label = "TS SWT Green Tea: 4.9\nTS Alergon Cookies: 4.9\nTS Kecap Manis: 4.9\nTS Stevia: 4.8\nTS Beras Merah: 4.8\nWRP Active Body Shape: 4.8\nWRP Fruitbar Apricot Raisin: 4.6",
           color = "darkgreen",
           size = 3) +
  theme_minimal() +
  labs(x = "Rating",
       subtitle = "Density plot dari rating",
       title = "Sebaran rating yang diberikan oleh member di\nkategori dapur makanan",
       caption = "Scraped and Visualized\nusing R\nikanx101.com") +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank())
```

Ternyata mayoritas produk memiliki rating yang baik (diatas skala `4`). Hanya sebagian kecil produk saja yang memiliki rating dibawah `3.5`.

Penasaran produk apa saja yang mendapatkan nilai rendah di antara produk-produk yang bergelimang rating bagus?

```{r,echo=FALSE}
print("Produk yang memiliki rating di bawah 3.5")
clean_data %>% 
  filter(rate_no<3.5) %>% 
  arrange(desc(rate_no)) %>% 
  select(-deskripsi)
```

Hanya ada `6` produk yang memiliki rating di bawah `3.5`. _Special cases_ ada pada __Chocomory__ dan __Gado Telur__:

- Hanya ada `3` _member_ saja yang memberikan _rating_ dan _review_ pada produk __Chocomory__.
- Belum ada _member_ yang memberikan _rating_ dan _review_ pada produk __Gado Telur Siap Saji__.

---

# _What's Next?_

## Beberapa Produk yang Ada di Kategori __Dapur Makanan__

Ternyata setelah saya lihat dengan seksama, ada beberapa pasang produk dan kompetitornya yang ada di sana. Menarik jika kita lakukan analisa _head-to-head_ dari pasangan produk tersebut.

Apa saja analisanya?

> Tentunya analisa terkait dengan data komentar _member_ yang berupa _free text_.

Hal yang bisa dilakukan:

1. _Wordcloud_,
1. _Bigrams_,
1. _Topic modelling_
1. _Crosswords_
1. _Log odds ratio_

Nah, ada satu hal baru yang ingin saya lakukan (karena dari dulu belum sempat mengerjakannya). Apa itu? _Sentiment analysis_. 

Doakan semoga yang terakhir ini bisa dilakukan dengan baik _yah_.

Sekian dulu tulisan ini, hasil analisa komentar akan saya tulis di tulisan berikutnya.