---
title: "Text Clustering dengan R: Case Study Komentar Netizen Terhadap Produk Susu Oat"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list=ls())

setwd("~/ikanx101.github.io/_posts/home tester club/tulisan ketiga")

library(dplyr)
library(tidyr)
library(tidytext)
library(igraph)
library(ggplot2)
library(ggraph)

# ==============================================
# ambil data yang telah didapatkan
saved_rda = "hasil komen.rda"
load(saved_rda)

# kita simpan dulu data frame nya
df = data.frame(komen = c(temp[[1]],
                          temp[[2]],
                          temp[[3]]))
df$resp_id = 1:nrow(df)
```

Ternyata setelah saya lihat kembali _blog_ saya ini, sudah lama saya tidak menuliskan tentang _text analysis_. Semua tulisan saya terkait _text analysis_ bisa dibaca di [_link_ berikut ini](https://ikanx101.com/tags/#text-analysis).

_Nah_, kali ini saya akan mencoba satu hal baru yang sebenarnya sudah lama dipendam yakni _text clustering_ dengan metode _clustering_ yang sudah saya bahas di [tulisan ini](https://ikanx101.com/blog/clustering-R/).

> Ya betul, saya akan mengaplikasikan metode clustering pada data berupa teks!

Jadi, metode _clustering_ atau pengelompokkan juga bisa diaplikasikan menggunakan teknik _unsupervised learning_ ini. Tujuannya jelas, yakni: __mengelompokan data teks menjadi beberapa kelompok yang homogen__.

Buat rekan-rekan yang sudah terbiasa melakukan _text analysis_, biasanya untuk melakukan pengelompokan data teks, analisa yang digunakan adalah LDA (_Latent Dirichlet Allocation_). Saya pernah menggunakannya untuk [mengelompokan komen-komen netizen](https://ikanx101.com/blog/blog-posting-sunyi/) pada suatu _web series_ di __Youtube__.

Berbeda dengan LDA, prinsip yang digunakan saat ini adalah _clustering_ yang menurut saya lebih intuitif dan mudah untuk diikuti.

Saya mulai _yah_.

---

Data yang saya gunakan adalah data _review_ para konsumen __Tropicana Slim Oat Drink__ yang saya dapatkan dari situs __Hometester Club Indonesia__. _Oh iya_, kenapa saya penasaran melakukan analisa untuk produk ini? Karena menurut saya produk ini menawarkan alternatif minuman susu vegan yang sehat dengan rasa yang __pas__. Kalau tidak percaya, silakan dicoba _yah_.

Dulu, saya pernah juga [menganalisa _review_ produk-produk lain dari situs tersebut](https://ikanx101.com/blog/home-tester/).

Saya mendapatkan `45` buah _reviews_. Berikut adalah sampel _review_-nya:

```{r,echo=FALSE}
head(df)
```

### _Workflow_ Analisis

Dari data di atas, saya tidak bisa langsung melakukan _clustering_ karena data teks-nya masih sangat kotor. Setidaknya, saya harus melakukan beberapa _pre-processing_ sebagai berikut:

1. Mentransformasi semua _uppercase_ menjadi _lowercase_. 
1. Membuang semua _punctuation_.
1. Membuang semua _stopwords_ dan kata-kata tak bermakna.

Untuk melakukan ketiga proses di atas, saya menggunakan `library(tidytext)` dari `tidyverse`. Sementara daftar _stopwords_ saya himpun dari [rekapan _Github User_](https://raw.githubusercontent.com/ikanx101/ID-Stopwords/master/id.stopwords.02.01.2016.txt) yang saya _enrich_ dari data yang dihimpun. Cara _enrich_-nya adalah dengan membuat _bigrams_, lalu mendeteksi secara manual kata mana saja yang perlu dibuang.

> Kenapa harus _bigrams_? Kenapa bukan _wordcloud_?

Bagi saya, _bigrams_ menawarkan konteks dibanding kata semata. Maka harusnya saya bisa memilih kata-kata mana saja yang benar-benar tak bermakna untuk dibuang.

Sekarang saya akan buat langkah 1-3 serta _bigrams_ sebagai berikut:

```{r,message=FALSE,warning=FALSE,fig.retina = 4}
# kita ambil stopwords
stop = readLines("https://raw.githubusercontent.com/ikanx101/ID-Stopwords/master/id.stopwords.02.01.2016.txt")

# kita lakukan langkah 1-2
df = 
  df |>
  # lowercase
  mutate(komen = tolower(komen),
         komen = stringr::str_trim(komen)) |>
  # remove punctuation
  mutate(komen = gsub("[[:punct:]]|\\n|\\r|\\t"," ",komen),
         komen = stringr::str_trim(komen)) |>
  unnest_tokens("words",komen) |>
  # remove stopwords
  filter(!words %in% stop)

# mengembalikan ke bentuk awal
raw = 
  df |> 
  group_by(resp_id) |> 
  summarise(komen = paste(words,collapse = " ")) |>
  ungroup()

# kita buat grafik bigram dulu
bigram_plot = 
  raw |>
  unnest_tokens("bigrams",komen,token = "ngrams",n = 2) |>
  group_by(bigrams)|>
  tally(sort = T) |>
  ungroup() |>
  head(30) |>
  separate(bigrams,into = c("from","to"),sep = " ") %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = 'fr') +
  geom_edge_bend(aes(edge_alpha=n),
                 show.legend = F,
                 color='darkred') +
  geom_node_point(size=1,color='steelblue') +
  geom_node_text(aes(label=name),alpha=0.4,size=3,repel = T) +
  theme_void()

bigram_plot

```

Dari _bigrams_ di atas, saya akan eliminasi beberapa kata yang tak bermakna menurut saya, seperti `but` dan `190ml`. Proses ini saya lakukan secara iteratif hingga semua kata tak bermakna hilang. Berikut adalah hasil akhir _bigrams_-nya:

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.retina=4}
rm(list=ls())
# ==============================================
# ambil data yang telah didapatkan
saved_rda = "hasil komen.rda"
load(saved_rda)

# kita simpan dulu data frame nya
df = data.frame(komen = c(temp[[1]],
                          temp[[2]],
                          temp[[3]]))
df$resp_id = 1:nrow(df)

# kita ambil stopwords
stop = readLines("https://raw.githubusercontent.com/ikanx101/ID-Stopwords/master/id.stopwords.02.01.2016.txt")
stop = c(stop,"but","190ml","aja","880kkal","80kkal","abis")

# kita lakukan langkah 1-2
df = 
  df |>
  # lowercase
  mutate(komen = tolower(komen),
         komen = stringr::str_trim(komen)) |>
  # remove punctuation
  mutate(komen = gsub("[[:punct:]]|\\n|\\r|\\t"," ",komen),
         komen = stringr::str_trim(komen)) |>
  unnest_tokens("words",komen) |>
  # remove stopwords
  filter(!words %in% stop)

# mengembalikan ke bentuk awal
raw = 
  df |> 
  group_by(resp_id) |> 
  summarise(komen = paste(words,collapse = " ")) |>
  ungroup()

# kita buat grafik bigram dulu
bigram_plot = 
  raw |>
  unnest_tokens("bigrams",komen,token = "ngrams",n = 2) |>
  group_by(bigrams)|>
  tally(sort = T) |>
  ungroup() |>
  head(30) |>
  separate(bigrams,into = c("from","to"),sep = " ") %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = 'fr') +
  geom_edge_bend(aes(edge_alpha=n),
                 show.legend = F,
                 color='darkred') +
  geom_node_point(size=1,color='steelblue') +
  geom_node_text(aes(label=name),alpha=0.4,size=3,repel = T) +
  theme_void()

bigram_plot

```
















