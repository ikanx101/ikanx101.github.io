---
title: "Untitled"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ALGORITMA PENYELESAIAN OPTIMISASI

Pada bagian ini kita akan membahas macam-macam algoritma yang digunakan untuk menyelesaikan masalah optimisasi.

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',fig.cap="Algoritma Penyelesaian Optimisasi"}
nomnoml::nomnoml("#direction: down
                 [Algoritma\nOptimisasi] -> [Metode eksak]
                 [Algoritma\nOptimisasi] -> [Metode aproksimasi]
                 
                 [Metode eksak] -> [Iteratif]
                 [Metode eksak] -> [Enumeratif]
                 
                 [Metode aproksimasi] -> [AdHoc\nHeuristic]
                 [Metode aproksimasi] -> [Metaheuristic]
                 ")
```

Secara garis besar ada dua kelompok besar algoritma optimisasi, yakni:

1. _Exact method_,
1. _Approximate method_.

Perbedaan keduanya adalah pada __konsep atau pendekatan apa yang digunakan__ untuk menyelesaikan masalah optimisasi. Kita akan bahas satu-persatu pada bagian selanjutnya.

Dalam beberapa kasus, kita bisa mendapatkan _exact method_ bisa untuk menyelesaikan masalah optimisasi dengan efisien. Namun di kasus lain yang lebih kompleks tidak demikian. Kelemahan utama metode _exact_ adalah pada waktu komputasinya yang relatif lebih lama.

## _Exact Method_

Ciri khas dari _exact method_ adalah metode ini menjamin penyelesaian yang optimal karena menggunakan pendekatan analitis [@franz]. Salah satu contoh metode eksak adalah _Simplex Method_.

## _Approximate Method_

Ciri khas dari _approximate method_ adalah metode ini tidak menjamin penyelesaian yang optimal karena bersifat _aproksimasi_ atau pendekatan atau hampiran[@geovani]. Oleh karena itu kita perlu melakukan definisi di awal __seberapa dekat__ nilai __hampiran__ tersebut bisa kita terima.

Metode ini bisa dibagi menjadi dua berdasarkan keterkaitannya dengan suatu masalah, yakni:

1. _Heuristic_, metode ini bersifat _problem dependent_. Artinya metode tersebut hanya bisa dipakai untuk jenis permasalahan tertentu.
    - Contoh: metode _nearest neighborhood_ hanya bisa dipakai untuk menyelesaikan masalah dalam lingkup _travelling salesperson problem_ (__TSP__).
1. _Meta heuristic_, metode ini bersifat _problem independent_. Artinya metode tersebut tidak tergantung dari jenis permasalahan tertentu. Contoh: 
    - _Genetic algorithm_.
    - _Simulated annealing_.
    - _Spiral optimization_ untuk menyelesaikan masalah _mixed integer non linear programming_ [@kun].
    - _Artifical bee colony algorithm_.
    
Namun demikian kedua metode ini bisa saling melengkapi dalam prakteknya.


# METODE _SIMPLEX_

Metode _simplex_ adalah salah satu metode yang paling umum digunakan dalam menyelesaikan permasalahan _linear programming_. Metode ini dikembangkan oleh seorang profesor matematika bernama George Dantzig^[https://en.wikipedia.org/wiki/George_Dantzig] pada 1947 pasca perang dunia II. Sedangkan nama _simplex_ diusulkan oleh Theodore Motzkin^[https://en.wikipedia.org/wiki/Theodore_Motzkin].

Metode _simplex_ menggunakan prosedur aljabar[@lieberman]. Namun _underlying concept_ dari metode ini adalah _geometric_.

## Metode Simplex dengan Ilustrasi Geometris

Jika kita bisa memahami konsep geometrinya, kita bisa mengetahui bagaimana cara kerjanya dan kenapa metode ini sangat efisien.

Saya akan ambil satu contoh masalah optimisasi sederhana untuk memberikan ilustrasi bagaimana cara kerja metode ini.

#### Contoh Masalah Optimisasi {-}

Cari $x_1,x2$ yang $\max{(Z = 3x_1 + 5x_2)}$ dengan _constraints_:

$$\begin{matrix}
x1 \leq 4  \\
2x_2 \leq 12 \\
3x_1 + 2x_2 \leq 18 \\
\text{serta } x_1 \geq 0, x_2 \geq 0 \\
\end{matrix}$$

Masalah di atas jika dibuat grafiknya:

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',fig.cap="Grafik Permasalahan Optimisasi"}
rm(list=ls())
f = function(x1){(18-3*x1)/2}
data.frame(x = 0:6) %>% 
  mutate(y = f(x)) %>% 
  ggplot() +
  geom_line(aes(x,y),
            color = "red") +
  scale_x_continuous(breaks = c(-1:10)) +
  scale_y_continuous(breaks = c(-1:10)) +
  coord_equal() +
  geom_vline(xintercept = 0,
             color = "black",
             size = 1.1) +
  geom_hline(yintercept = 0,
             color = "black",
             size = 1.1) +
  geom_vline(xintercept = 4,
             color = "red") +
  geom_hline(yintercept = 6,
             color = "red") +
  annotate("segment",
           x = 0, xend = 0,
           y = 0, yend = 6,
           color = "red") +
  annotate("segment",
           x = 0, xend = 4,
           y = 0, yend = 0,
           color = "red") +
  annotate("point",x = 0, y = 0,
           color = "darkgreen",
           size = 4) +
  annotate("point",x = 0, y = 6,
           color = "darkgreen",
           size = 4) +
  annotate("point",x = 2, y = 6,
           color = "darkgreen",
           size = 4) +
  annotate("point",x = 4, y = 3,
           color = "darkgreen",
           size = 4) +
  annotate("point",x = 4, y = 0,
           color = "darkgreen",
           size = 4) +
  annotate("point",x = 0, y = 9,
           color = "purple",
           size = 4) +
  annotate("point",x = 4, y = 6,
           color = "purple",
           size = 4) +
  annotate("point",x = 6, y = 0,
           color = "purple",
           size = 4) +
  annotate("text",x = 2, y = 3,
           color = "steelblue",
           label = "Feasible Region") +
  labs(x = "x1",
       y = "x2",
       title = "Grafik dari Permasalahan Optimisasi") 

```

\newpage

Titik-titik hijau merupakan __beberapa titik__ solusi yang _feasible_ karena berada pada area penerimaan seluruh _constraints_ yang ada. Titik hijau ini menjadi spesial karena berada pada perpotongan 2 garis _constraints_. Selanjutnya titik hijau ini akan didefinisikan sebagai __CPF__ (_corner point feasible_).

> _For a linear programming problem with n decision variables, each of its corner-point solutions lies at the intersection of n constraint boundaries._ [@lieberman]

Sedangkan titik ungu merupakan titik solusi non _feasible_ karena solusi yang ada tidak berlaku untuk semua _constraints_.

```{r,echo=FALSE,warning=FALSE,message=FALSE}
cpf = data.frame(
  `Titik-ke` = 1:5,
  CPF = c("(0, 0)", 
          "(0, 6)", 
          "(2, 6)", 
          "(4, 3)",
          "(4, 0)")
    )

cpf %>% knitr::kable(align = "c",caption = "Titik yang termasuk ke dalam CPF")
```

---

#### _Properties of CPF Solutions_ {-}

Untuk setiap permasalahan _linear programming_ yang memiliki _feasible solutions_ dan _feasible region_ yang terbatas, berlaku:

- __Property 1__: 
    - (a) If there is exactly one optimal solution, then it must be a __CPF solution__. 
    - (b) If there are multiple optimal solutions (and a bounded feasible region), then at least two must be adjacent CPF solutions.
- __Property 2__: There are only a __finite number__ of CPF solutions.
- __Property 3__: If a CPF solution has no adjacent CPF solutions that are better (as measured by Z), then there are no better CPF solutions anywhere. Therefore, __such a CPF solution is guaranteed to be an optimal solution__ (by Property 1), assuming only that the problem possesses at least one optimal solution (guaranteed if the problem possesses feasible solutions and a bounded feasible region).

_Properties_ di atas menjamin keberadaan solusi optimal pada CPF dari suatu masalah optimisasi _linear programming_.

---

Untuk mulai melakukan metode simplex kita perhatikan kembali grafik di atas. Kita bisa temukan beberapa pasang __CPF__ berbagi _constraint_ yang sama satu sama lain. 

Sebagai contoh:

1. $CPF_1$ dan $CPF_2$ berbagi _constraint_ yang sama, yakni saat $x_1 \geq 0$.
1. $CPF_2$ dan $CPF_3$ berbagi _constraint_ yang sama, yakni saat $x_2 \leq 6$.

Definisi umum:

> _For any linear programming problem with n decision variables, two CPF solutions are_ ___adjacent___ _to each other if they share_ $n-1$ _constraint boundaries._ _The two adjacent CPF solutions are connected by a line segment that lies on these same shared constraint boundaries. Such a line segment is referred to as an_ ___edge___ _of the feasible region._

_Feasible region_ di atas memiliki 5 _edges_ di mana setiap 2 _edges_ memotong / memunculkan __CPF__. Setiap __CPF__ memiliki 2 __CPF__ lainnya yang _adjacent_.

```{r,echo=FALSE,warning=FALSE,message=FALSE}
cpf = data.frame(
  `Titik-ke` = 1:5,
  CPF = c("(0, 0)", 
          "(0, 6)", 
          "(2, 6)", 
          "(4, 3)",
          "(4, 0)"),
  `Adjacent CPF` = c("(0, 6) dan (4, 0)",
                     "(2, 6) dan (0, 0)",
                     "(4, 3) dan (0, 6)",
                     "(4, 0) dan (2, 6)",
                     "(0, 0) dan (4, 3)")
    )

cpf %>% knitr::kable(align = "c",caption = "Adjacent CPF")
```

__CPF__ pada kolom pertama _adjacent_ terhadap dua __CPF__ di kolom setelahnya tapi kedua __CPF__ tersebut tidak saling _adjacent_ satu sama lain.

> ___Optimality test:___ _Consider any linear programming problem that possesses at least one optimal solution. If a CPF solution has no adjacent_ ___CPF___ _solutions that are better (as measured by_ $Z$_), then it must be an optimal solution._

Berdasarkan _optimality test_ tersebut, kita bisa mencari solusi optimal dari __CPF__ dengan cara mengambil __initial CPF__ untuk dites secara rekursif.

```{r,include=FALSE}
rm(list=ls())
Z = function(x1,x2){3*x1 + 5*x2}
```

- __STEP 1__ Pilih _initial_ __CPF__, misal $(0,0)$. Kita akan hitung nilai $Z(0,0)=$ `r Z(0,0)`. Bandingkan dengan _adjacent_ __CPF__-nya, yakni $Z(0,6)=$ `r Z(0,6)` dan $Z(4,0) =$ `r Z(4,0)`.
- __STEP 2__ Oleh karena $Z(0,6)$ memiliki nilai tertinggi, maka kita akan pilih titik ini di iterasi pertama. Kita akan bandingkan terhadap _adjacent_ __CPF__-nya, yakni: $Z(2,6)=$ `r Z(2,6)`. Perhatikan bahwa _adjacent_ __CPF__ $(0,0)$ sudah kita evaluasi pada langkah sebelumnya.
- __STEP 3__ Oleh karena $Z(2,6)$ memiliki nilai tertinggi, maka kita akan pilih titik ini di iterasi kedua. Kita akan bandingkan terhadap _adjacent_ __CPF__-nya, yakni: $Z(4,3)=$ `r Z(4,3)`. Kita dapatkan bahwa titik $(2,6)$ menghasilkan $Z$ tertinggi.

__Kesimpulan__: $(2,6)$ merupakan titik yang bisa memaksimumkan $Z$.

\newpage

### _Flowchart_ Metode Simplex dari Contoh Masalah

Secara garis besar, _flowchart_ dari metode simplex untuk masalah di atas adalah:

```{r out.width="45%",echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',fig.cap="Algoritma Metode Simplex"}
nomnoml::nomnoml("#direction: down,
                 [<start> start] -> [Cari CPF]
                 [Cari CPF] -> [<input> Set initial CPF]
                 [<input> Set initial CPF] -> [<choice> Optimality Test\nOptimal?]
                 [<choice> Optimality Test\nOptimal?] -> Yes [<end> end]
                 [<choice> Optimality Test\nOptimal?] -> No [Cari adjacent CPF\nTeroptimal]
                 [Cari adjacent CPF\nTeroptimal] -> [<choice> Optimality Test\nOptimal?]
                 ")
```

\newpage

Algoritma di atas akan sangat mudah dilakukan saat kita berhadapan dengan masalah optimisasi dengan 2 _decision variables_ (atau 3 _decision variables_). Pada contoh di atas ada $x_1,x_2$.

> Bagaimana jika masalah yang dihadapi memiliki banyak _decision variables_?

Tentunya kita tidak bisa melakukan analisa secara visual seperti di atas. Namun kita bisa menggunakan bantuan aljabar dan operasi baris elementer untuk menemukan solusi yang optimal.

## Transisi Geometris ke Aljabar

Pada penjelasan sebelumnya kita bisa melihat ilustrasi geometris dari suatu masalah optimisasi di mana solusi berada di __CPF__. Namun jika kita berhadapan dengan $n>2$ variabel, kita tidak bisa menggambarkan visualnya. Oleh karena itu kita akan menggunakan skema aljabar untuk menyelesaikannya. 

Ide dasarnya adalah dengan mengubah pertaksamaan yang ada di _constraints_ menjadi sebuah persamaan dengan menambahkan beberapa variabel _dummy_. Persamaan-persamaan tersebut akan kita jadikan SPL dan dicari solusinya dengan kondisi __semua kombinasi di mana__ $n-m$ __variabel dibuat sama dengan nol__ ($m$ banyaknya persamaan dan $n$ banyaknya variabel).

- $n-m$ variabel yang dibuat __nol__ disebut dengan _non basic variables_, 
- Sedangkan variabel $m$ sisanya disebut dengan _basic variables_. Solusi dari SPL ini disebut dengan _basic solution_ [@taha].

Dengan contoh masalah yang sama dengan sebelumnya, kita akan selesaikan sebagai berikut:

#### Masalah Optimisasi {-}

Cari $x_1,x_2$ yang $\max{(Z = 3x_1 + 5x_2)}$ dengan _constraints_:

$$\begin{matrix}
x1 \leq 4  \\
2x_2 \leq 12 \\
3x_1 + 2x_2 \leq 18 \\
\text{serta } x_1 \geq 0, x_2 \geq 0 \\
\end{matrix}$$


Pada _constraints_ yang mengandung pertaksamaan $\leq$, _right hand side_ menunjukkan batas dari _resources_ sementara _left hand side_ menunjukkan _usage_ dari _resources_. Selisih antara _rhs_ dan _lhs_ menunjukkan __sisa__ _resources_ yang tidak terpakai. Kita perlu mengubah pertaksamaan yang ada menjadi bentuk persamaan dengan cara menambahkan $u,v,w$ sebagai ___non negative slack variables___ [@taha].

Oleh karena itu kita tuliskan _constraints_ menjadi sebagai berikut:

$$\begin{matrix}
x1 + u = 4  \\
2x_2 + v = 12 \\
3x_1 + 2x_2 + w = 18 \\
\text{dengan } x_1 \geq 0, x_2 \geq 0, u \geq 0, v \geq 0, w \geq 0 \\
\end{matrix}$$

Perhatikan bahwa $m = 3$ dan $n = 5$ sehingga $n-m=2$. Maka kita akan buat semua kombinasi _non basic variables_ (berisi 2 variabel).

```{r,include=FALSE}
rm(list=ls())
var_ = c("x1","x2","u","v","w")
non_basic = combn(var_,2,simplify = F)
non_basic_d = data.frame(v1 = rep(NA,length(non_basic)),v2 = NA)
for(i in 1:length(non_basic)){
  temp = non_basic[[i]]
  non_basic_d$v1[i] = temp[1]
  non_basic_d$v2[i] = temp[2]
}

non_basic = non_basic_d
non_basic
```

```{r,echo=FALSE}
paste0("(",non_basic$v1,",",non_basic$v2,")")
```

Kemudian menyelesaikan _SPL_ yang ada pada kondisi _non basic variables_ tersebut __nol__. Dari masing-masing solusi yang ada, kita akan lihat apakah _feasible_ atau tidak? Serta dievaluasi nilai $z$-nya.

Berikut adalah algoritma dan tabel hasilnya:

```{r, warning=FALSE,message=FALSE}
# set SPL dari constraints
A = data.frame(x1 = c(1,0,3),
               x2 = c(0,2,2),
               u = c(1,0,0),
               v = c(0,1,0),
               w = c(0,0,1))
# rhs
c = c(4,12,18)
# obj function
obj_f = function(data){
  # filter var
  x1 = sol_val %>% filter(var %in% c("x1"))
  x2 = sol_val %>% filter(var %in% c("x2"))
  # ambil val
  if(nrow(x1) != 1){x1 = 0}else{x1 = x1$value}
  if(nrow(x2) != 1){x2 = 0}else{x2 = x2$value}
  return(3*x1 + 5*x2)
  }

# set template hasil
hasil = data.frame(non_basic_var = paste0("(",non_basic$v1,",",non_basic$v2,")"),
                   basic_var = NA,
                   solusi = NA,
                   z = NA)

# iterasi
for (i in 1:nrow(non_basic)) {
  # siap print basic var
  basic_var = var_[!grepl(non_basic$v1[i],var_)]
  basic_var = basic_var[!grepl(non_basic$v2[i],basic_var)]
  basic_var = paste(basic_var,collapse = ",")
  hasil$basic_var[i] = paste0("(",basic_var,")")
  
  # hitung solusi SPL
  B = A %>% select(-contains(non_basic$v1[i])) %>% select(-contains(non_basic$v2[i])) %>% as.matrix()
  if(det(B) == 0){sol_print = NA}
  else{
    sol = solve(B) %*% c
    sol_print = paste(row.names(sol),sol,sep = " = ")
    sol_print = paste(sol_print,collapse = "; ")
  }
  hasil$solusi[i] = sol_print

  # evaluasi obj function
  if(det(B) == 0){z_hit = NA}
  else{
    sol_val = data.frame(var = row.names(sol),value = sol)
    z_hit = obj_f(obj_f)
  }
  hasil$z[i] = z_hit
  }
```

```{r,echo=FALSE}
hasil_final = 
  hasil %>% 
  mutate(feasible = ifelse(grepl("\\-",solusi) | is.na(solusi),
                           "No",
                           "Yes")
         )

hasil_final %>% 
  rename("Non Basic Var" = non_basic_var,
         "Basic Var" = basic_var) %>% 
  knitr::kable(align = "c",caption = "Hasil Perhitungan Simplex dengan Metode Aljabar")
```

Terlihat di atas bahwa $\max z = 36$ terletak pada saat $x_1 = 2, x_2 = 6$. Sama persis dengan perhitungan dengan pendekatan geometris.

## Metode Simplex dengan _Tableau_

Pendekatan aljabar di atas bisa kita buat menjadi suatu operasi baris elementer di matriks. Berikut adalah contohnya:

### Operasi Baris Elementer Matriks _Simplex_

Cari $x,y$ sehingga $\max{(P = 5x + 4y)}$ dengan _constraints_:

$$\begin{matrix}
3x + 5y \leq 78  \\
4x + y \leq 36 \\
\text{serta } x \geq 0, y \geq 0 \\
\end{matrix}$$

Pada _constraints_ yang mengandung pertaksamaan $\leq$, _right hand side_ menunjukkan batas dari _resources_ sementara _left hand side_ menunjukkan _usage_ dari _resources_. Selisih antara _rhs_ dan _lhs_ menunjukkan __sisa__ _resources_ yang tidak terpakai. 

Kita perlu mengubah pertaksamaan yang ada menjadi bentuk persamaan dengan cara menambahkan $u,w$ sebagai ___non negative slack variables___ [@taha]. Fungsi objectif $P$ juga harus diubah (dipindah sisi namun $P$ tetap positif).

$$\begin{matrix}
3x + 5y + u = 78, \text{ dengan } u\geq 0  \\
4x + y + w = 36, \text{ dengan } w \geq 0 \\
-5x - 4y + P = 0 \\
\end{matrix}$$

Setelah itu kita buat matriks (dalam hal ini saya akan buatkan tabelnya) sebagai berikut:

```{r,echo=FALSE}
rm(list=ls())
simplex = data.frame(
  x = c(3,4,-5),
  y = c(5,1,-4),
  u = c(1,0,0),
  w = c(0,1,0),
  P = c(0,0,1),
  b = c(78,36,0)
)

simplex %>% knitr::kable("simple",caption = "Initial Condition Bentuk Matriks Simplex")
```

__STEP 1__ Kita akan pilih kolom yang memiliki nilai __negatif terbesar__ pada baris terakhir, yakni kolom $x$. Selanjutnya kita akan pilih baris mana yang akan menjadi pivot dengan cara menghitung rasio $\frac{b}{x}$ untuk semua baris dan memilih baris dengan __rasio terendah__.

```{r,echo=FALSE}
simplex = 
  simplex %>% 
  mutate(rasio = b/x)
simplex %>% knitr::kable("simple",caption = "Pemilihan Baris Pivot")
```

__STEP 2__ Kita akan buat baris 2 kolom $x$ menjadi bernilai `1`, caranya dengan melakukan OBE seperti: $Row_2 = \frac{Row_2}{4}$.

```{r,echo=FALSE}
simplex$rasio = NULL
simplex[2,] = simplex[2,] / 4
simplex %>% knitr::kable("simple",caption = "OBE Iterasi 1")
```

__STEP 3__ Sekarang tujuan kita selanjutnya adalah membuat kolom $x$ baris `1` dan `3` menjadi bernilai __nol__. Caranya adalah:

$$Row_1 = Row_1 - 3 Row_2$$

$$Row_3 = Row_3 + 5 Row_2$$

```{r,echo=FALSE}
simplex[1,] = simplex[1,] - 3*simplex[2,]
simplex[3,] = simplex[3,] + 5*simplex[2,]

simplex %>% knitr::kable("simple",caption = "OBE Iterasi 2")
```

__STEP 4__ Kita akan lakukan hal yang sama pada _step 1_, yakni memilih kolom dengan negatif terbesar. Yakni kolom $y$. Lalu kita akan hitung rasio setiap baris dan akan memilih rasio paling rendah.

```{r,echo=FALSE}
simplex = 
  simplex %>% 
  mutate(rasio = b/y)
simplex %>% knitr::kable("simple",caption = "Pemilihan Baris Pivot Kembali")
```

__STEP 5__ Maka kita akan pilih baris `1` menjadi pivot. Kolom $y$ pada baris `1` harus bernilai `1` sehingga kita harus membuat $Row_1 = \frac{4Row_1}{17}$.

```{r,echo=FALSE}
simplex$rasio = NULL
simplex[1,] = 4*simplex[1,] / 17
simplex %>% knitr::kable("simple",caption = "OBE Iterasi 3")
```

__STEP 6__ Kita akan buat klom $y$ di baris `2` dan `3` menjadi __nol__ dengan cara:

$$Row_2 = Row_2 - \frac{Row_1}{4}$$

$$Row_3 = Row_3 + \frac{11 Row_1}{4}$$


```{r,echo=FALSE}
simplex[2,] = simplex[2,] - simplex[1,] / 4
simplex[3,] = simplex[3,] + (2.75*simplex[1,])

simplex %>% knitr::kable("simple",caption = "OBE Iterasi 4")
```

Dari tabel terakhir di atas, kita bisa menuliskan $x=6,y=12$ dan nilai $\max{(P)}=78$. Bagaimana dengan nilau $u$ dan $w$? Karena tidak ada nlai `1` ditemukan pada kolom variabel tersebut, kita bisa simpulkan bahwa $u=0,w=0$.


## Metode _Branch and Bound_ untuk _MILP_

Metode _simplex_ adalah metode eksak yang digunakan untuk menyelesaikan _linear programming_. Solusi yang dihasilkan merupakan bilangan _real_ atau kontinu. Pada _MILP_, variabel yang terlibat sangat beragam (_integer_, _binary_, dan kontinu). Membulatkan bilangan solusi _linear programming_ untuk mendapatkan solusi _integer_ atau _binary_ dari suatu masalah _MILP_ tidak menjamin keoptimalan tercapai.

Oleh karena itu, kita akan melakukan pendekatan tertentu dari _linear programming_ agar hasilnya bisa digunakan di _MILP_.

### _Relaxation of Discrete Optimization Models_

Salah satu pendekatan yang bisa dilakukan adalah melakukan _constraint relaxation_ [@benoit].

#### Definisi {-}

Model $R$ disebut dengan _constraint relaxation_ dari model $P$ jika:

- Setiap _feasible solution_ dari $P$ juga _feasible_ di $R$.
- $P$ dan $R$ memiliki fungsi objektif yang sama.

#### Contoh {-}

Berikut adalah _original MILP_:

$$\min_{x,y} 7x_1 + x_2 + 3 y_1 + 6y_2$$

$$\text{s.t. } x_1 + 10 x_2 + 2 y_1 + y_2 \geq 100$$

$$y_1 + y_2 \leq 1$$

$$x_1,x_2 \geq 0,y_1,y_2 \in \{0,1\}$$

___Relaxation I___ : _relax constraints RHS_

$$\min_{x,y} 7x_1 + x_2 + 3 y_1 + 6y_2$$

$$\text{s.t. } x_1 + 10 x_2 + 2 y_1 + y_2 \geq 50$$

$$y_1 + y_2 \leq 1$$

$$x_1,x_2 \geq 0,y_1,y_2 \in \{0,1\}$$

___Relaxation II___ : _Drop constraint_

$$\min_{x,y} 7x_1 + x_2 + 3 y_1 + 6y_2$$

$$\text{s.t. } x_1 + 10 x_2 + 2 y_1 + y_2 \geq 100$$

$$x_1,x_2 \geq 0,y_1,y_2 \in \{0,1\}$$

___Relaxation III___ : _remove integrality_

$$\min_{x,y} 7x_1 + x_2 + 3 y_1 + 6y_2$$

$$\text{s.t. } x_1 + 10 x_2 + 2 y_1 + y_2 \geq 100$$

$$y_1 + y_2 \leq 1$$

$$x_1,x_2 \geq 0, 0 \leq y_1,y_2 \leq 1$$

### _Linear Programming Relaxation_

#### Definisi {-}

_LP relaxation_ dari _MILP_ dibentuk dengan memperlakukan variabel diskrit sebagai variabel kontinu sambil mempertahankan semua _constraints_ yang ada [@benoit].

$$y \in \{0,1\} \Rightarrow 0 \leq y \leq 1$$

\newpage

Oleh karena itu bisa terjadi hal sebagai berikut:

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',fig.cap="Solusi LP Relaxation"}
knitr::include_graphics("Screenshot from 2021-10-30 17-35-28.png")
```

Apakah _LP relaxation_ menjamin mendapatkan hasil yang _valid_?

Berikut adalah sifat dari _LP relaxation_:

1. Jika _LP relaxation_ _infeasible_, maka model _MILP_ asalnya juga. 
1. Hasil optimal _LP relaxation_ dari _MILP_ yang bertujuan untuk maksimisasi berada pada _upper bound_.
1. Hasil optimal _LP relaxation_ dari _MILP_ yang bertujuan untuk minimisasi berada pada _lower bound_.
1. Jika suatu solusi optimal _LP relaxation_ ternyata _feasible_, maka solusi tersebut optimal di model _MILP_ asalnya. 

### Algoritma _Branch and Bound_

Algoritma _branch and bounds_ mengkombinasikan beberapa strategi _relaxation_ secara iteratif untuk memilih kemungkinan solusi paling optimal. 

#### Ilustrasi {-}

Perhatikan contoh berikut:

$$\max z = 4 x_1 - x_2$$

$$\text{s.t. } 7 x_1 - 2 x_2 \leq 14$$

$$x_2 \leq 3$$

$$2 x_1 - 2 x_2 \leq 3$$

$$x_1,x_2 \in \mathbb{Z}^+$$

Misalkan $S$ adalah himpunan solusi _feasible_ dari _LP relaxation_ (dibuat suatu _LP relaxation_ dengan $x$ berupa variabel kontinu). Menggunakan metode simplex kita bisa dapatkan $x_1 = 2.857143 , x_2 = 3, z = 8.428571$.

Kita misalkan $z* = - \infty$, karena $x_1$ bukan integer, maka kita akan uat _branch out_ dari variabel ini.

$$S_1 = S \cap \{x:x_1 \leq 2\}$$

$$S_2 = S \cap \{x:x_1 \geq 3\}$$

```{r out.width="60%",echo=FALSE,fig.align='center',fig.retina=10,fig.cap="Branch Out Tahap I"}
nomnoml::nomnoml("[S|z = 8.428571|z*=-inf] -> x1<=2 [S1]
                 [S|z = 8.428571|z*=-inf] -> x1>= 3 [S2]")
```

Kita akan evaluasi kembali dengan _LP relaxation_ yang baru.

- Pada $S_1$ kita dapatkan dengan metode _simplex_ solusinya adalah $x_1 = 2, x_2 = 0.5, z = 0.75$. Oleh karena itu, kita akan _branch out_ kembali dengan pemecahan sebagai berikut:

$$S_{11} = S \cap \{x:x_2 = 0\}$$

$$S_{12} = S \cap \{x:x_2 \geq 1\}$$


- Pada $S_2$ kita dapatkan bahwa kondisi $x_1 \geq 3$ membuat model menjadi _infeasible_. Kita akan hentikan _branch out_ dari $S_2$.

```{r out.width="60%",echo=FALSE,fig.align='center',fig.retina=10,fig.cap="Branch Out Tahap II"}
nomnoml::nomnoml("[S|z = 8.428571|z*=-inf] -> x1<=2 [S1]
                 [S|z = 8.428571|z*=-inf] -> x1>= 3 [S2]
                 [S1] -> x2=0 [S11]
                 [S1] -> x2>=1 [S12]
                 ")
```

Kita lakukan kembali _LP relaxation_ pada $S_{11}$ dan $S_{12}$ sebagai berikut:

- Pada $S_{12}$, metode simplex menghasilkan solusi $x_1 = 2, x_2 = 1, z = 7$. Kita akan _update_ nilai $z* = 7$.
- Pada $S_{11}$, metode simplex menghasilkan solusi $x_1 = 1.5, x_2 = 0, z = 6$. Karena $z < z*$, maka tidak ada lagi _branch out_.

#### Kesimpulan {-}

Solusi optimal didapatkan pada $S_{12}$.

```{r,include=FALSE}
rm(list=ls())

# memanggil libraries
library(dplyr)
library(ompr)
library(ompr.roi)
library(ROI.plugin.glpk)

# membuat model
milp_new = 
  MIPModel() %>% 
  
  # membuat 2 variabel integer
  add_variable(x1,type = "continuous",lb = 0) %>% 
  add_variable(x2,type = "continuous",lb = 0) %>% 
  
  # set obj function
  set_objective(4*x1 - x2,
                "max") %>% 
  
  # menuliskan semua constraints
  add_constraint(7*x1 - 2*x2 <= 14) %>% 
  add_constraint(x2 <= 3) %>% 
  add_constraint(2*x1 - 2*x2 <= 3) %>% 
  add_constraint(x1 <= 2) %>% 
  add_constraint(x2 == 0)

result = solve_model(milp_new, with_ROI(solver = "glpk", verbose = TRUE))

result %>% get_solution(x1)
result %>% get_solution(x2)

```

## __R__ _Library_ untuk Metode _Simplex_

Pada bagian sebelumnya, kita telah membahas bagaimana cara melakukan metode _simplex_ dengan operasi baris elementer. 

> Apakah proses operasi tersebut bisa diformalkan dalam bentuk algoritma atau __R__ _codes_?

Salah satu dari sekian banyak _packages_ yang memiliki _function_ metode _simplex_ yang siap pakai adalah `library(boot)` [@boot]. Pada bagian ini, kita akan membahas salah satu _function_ pada _library_ tersebut.

Fungsi `simplex()` dari `library(boot)` digunakan untuk menyelesaikan masalah optimisasi linear  $ax$ dengan _constraints_ $A_1x \leq b_1$, $A_2x \leq b_2$, $A_3x \leq b_3$, dan $x \geq 0$. Secara _default_, _function_ ini akan mengukur _minimize_. Namun kita bisa mengubahnya menjadi _maximize_.

### Penggunaan `simplex()`

Penggunaannya adalah sebagai berikut:

```
simplex(a, A1 = NULL, b1 = NULL, A2 = NULL, b2 = NULL, A3 = NULL,
        b3 = NULL, maxi = FALSE, n.iter = n + 2 * m, eps = 1e-10)
```

Dimana:

- `a` = _vector_ yang merupakan koefisien dari _objective function_.
- `A1` = merupakan matriks berisi koefisien dari constraints bertipa $\leq$.
- `b1` = _vector_ pasangan dari matriks `A1`. Harus berisi _non-negative_.
- `A2` = merupakan matriks berisi koefisien dari constraints bertipa $\geq$.
- `b2` = _vector_ pasangan dari matriks `A2`. Harus berisi _non-negative_. Perhatikan bahwa _constraints_ $\geq 0$ secara _default_ sudah masuk.
- `A3` = merupakan matriks berisi koefisien dari constraints bertipa $=$.
- `b3` = _vector_ pasangan dari matriks `A3`. Harus berisi _non-negative_. Perhatikan bahwa _constraints_ $\geq 0$ secara _default_ sudah masuk.
- `maxi` = _logical_, secara _default_ akan mencari _minimize_.

#### Catatan Khusus {-}

Penulis _packages_ ini memberikan suatu catatan khusus, yakni:

> _The method employed here is suitable only for relatively small systems._

### Contoh Penggunaan `simplex()`

Saya akan ambil contoh masalah _linear programming_ sebagai berikut:

$$\text{maximize: } 7x_1 + 3x_2 + x_3$$

$$\text{subject to: } \begin{matrix}
6x_1 + 4x_2  + 5x_3 \leq 60 \\ 8x_1 + x_2 + 2x_3 \leq 80 \\ 9x_1 + x_2 + 7x_3 \leq 70 \\ x_1,x_2,x_3 \geq 0
\end{matrix}$$

```{r}
rm(list=ls())
# panggil library
library(boot)

# set objective function
obj = c(7, 3, 1)
# membuat matriks A1
c1 = c(6, 4, 5)
c2 = c(8, 1, 2)
c3 = c(9, 1, 7)
A1 = rbind(c1,c2,c3)
# membuat rhs dari matriks A1
b1 = c(60, 80, 70)
# solving masalah optimisasi
simplex(a = obj, A1 = A1, b1 = b1,maxi = TRUE)

```

```{r,include=FALSE}
detach("package:boot", unload = TRUE)
```

## _Post-Optimality Analysis_

_Post-optimality analysis_ adalah analisa yang dilakukan pasca kita telah menemukan _optimal solution_ dari hasil perhitungan. Contohnya kita bisa melakukan __reoptimisasi__.

## _Sensitivity Analysis_

Salah satu proses dalam membuat model optimisasi adalah _parameter estimation_. Ada kalanya perubahan data mengakibatnya berubahnya suatu parameter. _Sensitivity analysis_ bertujuan untuk mengidentifikasi parameter yang sensitif (parameter yang harus dihitung dengan baik untuk menghindari kesalahan saat mencari solusi optimal).

