---
title: "Belajar Banyak Dari Shopee National Data Science Competition 2020"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("/cloud/project/_posts/Soapy NDSC")
#setwd("~/Documents/ikanx101/_posts/Soapy NDSC")
library(dplyr)
library(EBImage)
library(ggplot2)
```

Sore ini adalah akhir dari rangkaian acara __Shopee National Data Science Competition 2020__. Suatu kompetisi yang sangat seru dan berbeda dengan [kompetisi _data science_ yang dulu](https://passingthroughresearcher.wordpress.com/2018/11/15/belajar-dari-finhacks-id-2018/) pernah saya ikuti. Walaupun _gak_ menang dan hanya mendapatkan peringkat yang _gak_ sebegitu bagusnya, saya ingin bercerita mengenai pengalaman seru ini.

---

# Pendaftaran

Di awal tahun 2020, ada salah seorang teman kuliah saya dulu di Matematika ITB 2004 mengirimkan pesan _WhatsApp_. Ia menginformasikan bahwa ada kompetisi _data science_ yang akan diselenggarakan oleh Shopee pada bulan Maret 2020. Kompetisi itu bertajuk _National Data Science Competition_ (NDSC). Ada `2` kelas yang dipertandingkan:

1. _Beginner_.
1. _Advance_.

Kompetisi itu bisa diikuti secara perorangan dan tim. Sebagaimana pengalaman saya di kompetisi sebelumnya, alangkah lebih baik jika mengikutinya secara tim. Oleh karena itu, kami coba mencari lagi siapa yang bisa diajak kolaborasi bareng. Dapatlah `2` orang tambahan:

1. Satu orang merupakan teman seangkatan kami dulu.
1. Satu orang lainnya merupakan rekan kerja teman saya yang menginformasikan adanya kompetisi.

Setelah membentuk tim, kami mendaftar. Awalnya, kami kira bisa mendaftar di kelas _beginner_, ternyata pada saat pendaftaran, tim panitia dari Shopee benar-benar menyeleksi peserta dengan ketat. Singkat cerita, kami (terpaksa) mendaftar di kelas _advance_.

> Tenang saja, rekan kerja saya yang satu ini jago banget kok.

Ujar teman saya itu. _Hehe_

---

# Pandemi Covid

Tidak disangka pada bulan Maret 2020, negara api (baca: pandemi Covid 19) menyerang Indonesia. Perhelatan yang awalnya akan dilakukan dengan cara `karantina` peserta di suatu tempat selama seharian penuh ternyata diundur ke waktu yang tidak bisa ditentukan.

Sampai akhirnya pada awal bulan November 2020, _email_ surat cinta itupun datang.

Kompetisi akan tetap digelar secara _online_ menggunakan platform __Kaggle__ pada `28 November 2020`. Lalu semua tim diharapkan untuk bisa mendaftar ulang jika ada perubahan komposisi anggota.

Nah, pada waktu ini, rekan kerja teman saya itu tiba-tiba menghilang dari grup _WhatsApp_ yang kami bentuk. 

> _But the show must go on(line)!_

_Bismillah_, kami tetap maju dengan komposisi yang ada. _Toh_ niat kita awalnya bukan untuk menang tapi untuk mencari pengalaman saja.

---

# _Pre Competition_: 22 November 2020

Seminggu tepat sebelum hari kompetisi, ada _email_ surat cinta lagi. Setiap tim diwajibkan mengikuti _pre competition_ yang diadakan di __Kaggle__. Apa itu?

## _Problem Statement_

```{r fig.width="60%",echo=FALSE}
plot = readImage("problem.png")
plot(plot)
```

_Shopee_ mengedepankan _fairness_ terhadap semua barang yang dijual oleh _seller_-nya. Bisa jadi sepasang barang memiliki _title_ berbeda dan poto yang sedikit berbeda TAPI pada kenyataannya merupakan sepasang barang yang sama.

> Mungkin selama ini kita hanya mengetahui _fraud_ berupa penipuan yang ada di _marketplace_. Bisa jadi _fraud_ dilakukan dengan cara yang halus semacam ini.

Jadi tujuan _pre competition_ kali ini adalah membuat model _machine learning_ yang bisa memprediksi apakah sepasang barang merupakan barang yang sama atau beda dengan bermodalkan informasi:

1. Sepasang _titles_ barang.
1. Sepasang _images_ barang.

Data yang digunakan murni hanya `6` variabel saja!

```{r,echo=FALSE}
print("Contoh dataset yang diberikan:")
data = read.csv("new_training_set.csv")
head(data,5)
```

Dataset di atas ada `10.181` baris. Sedangkan data _images_ melebihi 1 GB ukurannya.

### Bagaimana cara menyelesaikannya?

Melihat data di atas, kami murni menghadapi _unstructured data_. Jadi langkah awal yang harus kami lakukan adalah mengekstrak _features_ variabel _titles_ dan _images_. Tentunya variabel _titles_ harus dibersihkan dulu dari tanda baca yang tidak diperlukan.

Setelah berdiskusi, maka ada beberapa _features_ yang akan kami ekstrak:

- _Titles_
  - Berapa banyak kata dari dua _titles_ barang?
  - Berapa banyak karakter dari dua _titles_ barang?
  - Berapa banyak kata yang sama dari dua _titles_ barang?
  - Berapa banyak _n-grams_ dari dua _titles_ barang? Terkait _n-grams_ ini, kami sampai menghitung kesamaan __bigrams__ hingga __7-grams__.
  - Berapa banyak angka yang sama dari dua _titles_ barang?
  - Berapa banyak huruf yang sama dari dua _titles_ barang? Ini kami hitung dari huruf __a__ sampai __z__.
  - Berapa jarak relatif antara dua vektor _character_ dari dua _titles_ barang?
  - Berapa jarak relatif antara dua vektor _character_ dari dua _titles_ barang (setelah dihilangkan semua angka)?
- _Images_. Ternyata apa yang saya lakukan [beberapa waktu lalu](https://ikanx101.com/blog/comparison-improvement/) saat _ngoprek_ data _images_ sangat berguna sekali.
  - Menghitung korelasi dari dua matriks _images_.
  - Menghitung proporsi kesamaan dua matriks _images_ untuk berbagai nilai sensitivitas.
  
Jadi kami fokus untuk mengekstrak semua informasi yang bisa diekstrak dari hari Minggu sampai Kamis (26 November 2020).
  
Singkat cerita, dari 4 variabel penting (2 _titles_ dan 2 _images_), kami berhasil mendapatkan `48` _features_. 

> _Features_ itu apa sih? Secara simpel, _features_ bisa saya katakan sebagai variabel numerik.

Oh iya, untuk mengekstrak _features_ dari `10.181` pasang _images_, saya membutuhkan waktu `1` jam penuh.

### Membuat model _machine learning_

Ada hal yang menarik saat kami mulai mengerjakan _pre competition_ ini. Pihak _Shopee_ merekomendasikan para peserta untuk menggunakan __Phyton__ daripada bahasa _data science_ lainnya.

Kami sebagai _R User_ garis keras merasa tertantang untuk tetap mengerjakannya dengan __R__. Ada satu dugaan dari saya:

> Jangan-jangan solusinya menggunakan deep learning.

Kenapa? Karena [_TensorFlow_](https://ikanx101.com/blog/deep-nutrisari/) yang digunakan untuk _Artificial Neural Network_ dibangun berbasis _Phyton_.

Harusnya tidak masalah, karena _TensorFlow_ bisa digunakan di __R__ juga.

Saya akhirnya mencoba membuat model _deep learning_, sementara teman saya yang lain _ngoprek_ _Support Vector Machine_ dan _XGBLinear_.

Hasilnya bagaimana?

Kami masih belum puas dengan _score_ yang dihasilkan saat dilakukan validasi.

### _Submission_ Jawaban Pertama: 26 November 2020

Di Kamis pagi, saya coba iseng membuat model _machine learning_ menggunakan _Random Forest Algorithm_. Tanpa disangka, _validation score_ yang saya dapatkan lebih tinggi dibandingkan model _deep learning_ yang saya buat sebelumnya.

Saat saya coba masukkan `data test pre competition` ke dalam model, lalu saya _submit_ ke _Kaggle_, saya terkejut karena mendapatkan nilai yang cukup tinggi: `0.89583` (max nilai = 1).

```{r fig.width="60%",echo=FALSE}
plot = readImage("percobaan 1.jpg")
plot(plot)
```

Walaupun tidak termasuk ke dalam `10` besar, tapi _score_ `0.89583` masuk ke dalam __TOP 5__ _score_ teratas.

Kok bisa?

> Jadi ada beberapa tim yang memiliki _score_ yang sama.

```{r,echo=FALSE,fig.retina=10}
data = read.csv("precomp.csv")
data = janitor::clean_names(data)

data %>% 
  ggplot(aes(x = score)) +
  geom_density(fill = "darkred",
               alpha = .4) +
  geom_vline(xintercept = 0.89583,
             color = "steelblue") +
  theme_minimal() +
  annotate("label",
           x = .8,
           y = 3,
           label = "Posisi tim saya\n0.89583") +
  labs(title = "Sebaran Score Para Tim yang Berlaga di Pre Competition",
       subtitle = "Shopee National Data Science Competition 2020",
       labs = "Visualized using R\nikanx101.com",
       x = "Score",
       y = "Density") +
  theme(axis.text.y = element_blank())

```

Pada _pre competition_ ini, ada `r length(unique(data$team_name))` buah tim yang berkompetisi.

Sebagai orang yang biasa berkutat terkait otomasi di __R__, mendapatkan _prediction score_ segitu sudah membahagiakan bagi saya pribadi.

Analoginya seperti seorang tukang gado-gado yang memasak _beef wellington_ dan diberikan pujian _good effort_ oleh __Gordon Ramsay__. _hehe_.

---

# _Competition Day_: 28 November 2020

Akhirnya hari yang dinanti datang juga. Acara dimulai pada pukul 10.00 WIB dengan sambutan-sambutan dari pihak _Shopee_ dan Menristek (Prof. Bambang Brodjonegoro).

Seperti biasa, saat dibuka forum _QnA_ di _live chat_ _Zoom_, ada saja pertanyaan-pertanyaan kocak yang ditanyakan para peserta iseng. Berikut skrinsutnya:

```{r fig.width="60%",echo=FALSE}
print("Boleh pakai excel?")
plot = readImage("excel.jpeg")
display(rotate(plot,45))

print("Boleh telepon rekan setim?")
plot = readImage("telepon.jpeg")
display(rotate(plot,45))

print("Apakah perlu kirim installernya?")
plot = readImage("installer.jpg")
display(plot)

print("Mimin apa kabar?")
plot = readImage("kabar.jpeg")
display(rotate(plot,45))
```

Pada sesi _QnA_ ini, ternyata _Shopee_ memperbolehkan penggunaan bahasa lain seperti __R__ dan _Matlab_.

### Pukul 11.00 WIB

Kompetisi kelas dimulai tepat pukul 11.00 WIB via _Kaggle_. Ternyata masalah yang dihadapi masih sama seperti masalah di _pre competition_.

Berikut adalah data yang digunakan pada kompetisi tadi siang:

```{r,echo=FALSE}
data = read.csv("new_test_set.csv")
head(data,10)
```

Ada `32.580` baris pasang data beserta 2 GB _images_ yang harus diselesaikan selama `3` jam.

Awalnya kami akan menggunakan model _random forest_ kemarin yang sudah jadi dengan beberapa modifikasi penambahan beberapa _features_ pada variabel _character_.

Secara paralel,