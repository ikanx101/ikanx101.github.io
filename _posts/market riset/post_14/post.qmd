---
title: "Anomaly Detection dalam Survei Online dan Bagaimana Mendeteksinya dengan Statistik / Machine Learning"
format:
  gfm:
    html-math-method: webtex
fig-dpi: 500
fig-width: 8
fig-height: 4.5
editor: visual
execute:
  warning: false
error: false
---

```{r}
#| include: false

setwd("~/ikanx101.github.io/_posts/market riset/post_14")

rm(list=ls())
set.seed(20921004)
```

Sepanjang karir saya di industri market riset, metode _online survey_ merupakan salah satu metode yang paling saya tak rekomendasikan untuk dilakukan. Alasannya sederhana: __kita tidak bisa memastikan siapa yang mengisi dan apakah diisi dengan benar__. Walaupun _online survey_ memiliki keuntungan secara _timeline_ pengumpulan data yang cepat.

Namun saat pandemi kemarin, mau tak mau (hampir) semua _project_ market riset harus dilakukan secara _online survey_. Untuk mengurangi bias dan pengisian bohong, kami coba membuat sistem rekrutmen responden sehingga kita bisa memastikan responden pengisi survey adalah benar-benar target responden yang diinginkan. Namun tetap kita tak bisa memastikan apakah isi kuesioner itu sudah __baik dan berkualitas__.

Setidaknya ada beberapa tipe responden yang bisa merusak kualitas data hasil _online survey_:

1. _Speedsters_: mengisi secara cepat di luar kewajaran.
1. _Straightliners_: mengisi semua pertanyaan secara seragam.
1. _Random clickers_: mengisi semua pertanyaan secara acak.
1. *Flip-flopers*: jawaban kontradiktif dalam satu survei.  
1. *Duplicate Responses**: satu orang responden mengisi survey berkali-kali.  

Oleh karena itu, tantangan terbesarnya adalah bagaimana melakukan _anomaly detection_ dalam _online survey_ hanya berbekal isi dari jawaban responden.

Untuk itu setidaknya ada dua cara untuk mendeteksi keberadaan anomali pada data hasil survey:

1. Cara sederhana menggunakan analisa statistika deskriptif:
    - Mendeteksi _outlier_ pada waktu pengisian survey dari semua responden. Waktu penyelesaian survei abnormal (terlalu cepat/lambat).
    - menghitung variasi jawaban untuk melihat apakah responden termasuk _straightliners_ atau *flip-flopers*.
1. Cara menggunakan _machine learning_: membuat model _isolation forest_ dari data untuk mendeteksi anomali.

Saya akan coba mendemokan kedua cara di atas menggunakan __R__ sebagai berikut:

## Membuat Data Survey _Dummy_ (1000 Responden)

Kita simulasi data survei dengan:  

- **Variabel**: Usia, Jenis Kelamin, 5 pertanyaan skala _likert_ (skala 1-5).  
- Anomali yang hendak dicari:  
  - _Speedsters_ (waktu jawab < 30 detik).  
  - _Straightliners_ (jawaban sama untuk semua pertanyaan).  
  - *Flip-flopers* (misal: jawaban ekstrem seperti 1 dan 5 bersamaan).  

```{r}
library(dplyr)
library(tidyr)

# Buat data dummy
n = 1000
data = tibble(
  id     = 1:n,
  usia   = sample(18:60, n, replace = TRUE),
  gender = sample(c("L", "P"), n, replace = TRUE),
  q1     = sample(1:5, n, replace = TRUE),
  q2     = sample(1:5, n, replace = TRUE),
  q3     = sample(1:5, n, replace = TRUE),
  q4     = sample(1:5, n, replace = TRUE),
  q5     = sample(1:5, n, replace = TRUE),
  waktu_jawab = rpois(n, lambda = 90)  # Waktu dalam detik
)

# banyak responden yang anomali
n_anom_speed = 101
n_aom_strait = 30
n_aom_inkon  = 20

# Tambahkan fraud: Speedsters (waktu < 30 detik)
data$waktu_jawab[sample(1:n, n_anom_speed)] = rpois(n_anom_speed, lambda = 30)

# Tambahkan fraud: Straightliners (jawaban sama semua)
data[sample(1:n, n_aom_strait), 4:8] = matrix(rep(sample(1:5, 
                                                         n_aom_strait, 
                                                         replace = TRUE), 
                                                  each = 5), 
                                              nrow = 5,
                                              ncol = n_aom_strait) %>% t()

# Tambahkan fraud: Flip-flopers (jawaban 1 dan 5 dalam survei yang sama)
data[sample(1:n, n_aom_inkon), 4:8] = replicate(n_aom_inkon, c(1, sample(2:4, 3), 5)) %>% t()

# Lihat sampel data
head(data,10) %>% knitr::kable()
```

## Cara Pertama: Statistika Deskriptif

### **a. Deteksi _Speedsters_ (Waktu Jawab Abnormal)**

Untuk mendeteksi _speedsters_, saya akan menggunakan **Z-score** sebagai _marker_ apakah responden tersebut _outlier_ atau bukan. Saya memilih _threshold_ sebesar $z_{\text{threshold}} = -2.5$. Maka untuk setiap $z_{\text{score}} <z_{\text{threshold}}$, maka responden tersebut termasuk _speedsters_.

> Jika Anda memiliki nilai $z_{\text{score}}$ sebesar -2.5, ini berarti nilai tersebut terletak 2.5 standar deviasi di bawah rata-rata. Nilai tersebut akan dianggap sebagai __tidak biasa atau signifikan__.

```{r}
# Hitung Z-score waktu_jawab
data = 
  data %>%
  mutate(
    z_score    = (waktu_jawab - mean(waktu_jawab)) / sd(waktu_jawab),
    is_speed   = ifelse(z_score < -2.5, TRUE, FALSE)  # Threshold Z-score
  )
```

```{r}
#| echo: false

# Visualisasi
library(ggplot2)
ggplot(data, aes(x = id, y = waktu_jawab, color = is_speed)) +
  geom_point() +
  scale_color_manual(values = c("darkgreen","red")) +
  labs(title = "Hasil Deteksi Speedsters (Waktu Jawab Abnormal)") %>% 
  labs(x = "Responden ke-",
       y = "Waktu mengisi survey",
       color = "Apakah Speedsters?") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

### **b. Deteksi _Straightliners_ (Pola Jawaban Sama)**  

Untuk mendeteksi keberadaan _straightliners_, kita cukup menghitung standar deviasi jawaban per responden. Jika standar deviasinya sama dengan 0, artinya responden tersebut _straightliners_.

```{r}
data =
  data %>%
  rowwise() %>%
  mutate(
    sd_jawaban  = sd(c(q1, q2, q3, q4, q5)),
    is_straight = ifelse(sd_jawaban == 0, TRUE, FALSE)
  )
```

```{r}
#| echo: false

# sampel responden yang termasuk straightliner
data %>% 
  filter(is_straight) %>% 
  select(id,usia,q1,q2,q3,q4,q5) %>% 
  head() %>% 
  knitr::kable()
```

### **c. Deteksi *Flip-flopers* (Jawaban Kontradiktif)**

Misalkan responden yang memberi nilai 1 dan 5 dalam survey yang sama padahal pertanyaan dirancang untuk konsisten satu sama lain.  

```{r}
data =
  data %>%
  mutate(
    min_jawaban = pmin(q1, q2, q3, q4, q5),
    max_jawaban = pmax(q1, q2, q3, q4, q5),
    is_flip     = ifelse(min_jawaban == 1 & max_jawaban == 5, TRUE, FALSE)
  )
```

```{r}
#| echo: false

# sampel responden yang termasuk straightliner
data %>% 
  filter(is_flip) %>% 
  select(id,usia,q1,q2,q3,q4,q5) %>% 
  head() %>% 
  knitr::kable()
```

### **d. Gabungkan Semua _Anomaly Indicators_**  

Sekarang kita gabungkan semua _anomaly indicators_ dan hitung berapa banyak responden yang terindikasi sebagai _"fraud"_.

```{r}
data =
  data %>%
  mutate(
    is_fraud = is_speed | is_straight | is_flip
  )
```

```{r}
#| include: false
# Hitung total fraud
n_fraud_1 = sum(data$is_fraud)  # Jumlah responden terindikasi fraud
```

Kita bisa mendapatkan `r n_fraud_1` orang responden yang terindikasi _"fraud"_.

---

## Cara Kedua: _Machine Learning_

Cara alternatif untuk mendeteksi anomali adalah menggunakan model _machine learning_. Model yang bisa kita gunakan bernama ___Isolation Forest___. Kita bisa memanfaatkan `library(solitude)` di __R__ untuk membuatnya.

### **a. Konsep Isolation Forest**  

_Isolation Forest_ adalah algoritma yang bekerja dengan prinsip:  

- **"Anomali lebih mudah diisolasi daripada data normal"**.  
- Algoritma membangun *random decision trees* (pohon keputusan acak) untuk mengisolasi setiap observasi.  
- Observasi yang memerlukan sedikit *split* untuk diisolasi dianggap sebagai anomali.  

Penjelasan di atas mungkin sulit dimengerti, maka saya akan gunakan analogi seperti ini:

**Analogi: Mencari Baju Kotor di Tumpukan _Laundry_**  

Bayangkan saya punya **keranjang laundry berisi 1000 baju**. Sebagian besar baju **normal** (bersih atau sedikit kotor), tapi ada beberapa yang **sangat kotor**. Saya hendak memisahkan baju normal dengan baju kotor.

> Jika kita memeriksa baju satu persatu, kita telah melakukan proses secara manual yang lama dan melelahkan.

Nah, kita bisa menggunakan cara _isolation forest_ dengan trik cerdas berikut:

1. Saya minta bantuan **10 teman** (_decision tree_) yang akan membantu.
1. **Langkah Acak**:  
   - Setiap teman mengambil **satu kriteria acak** (misal: "apa ada noda?", "apa baunya menyengat?").  
   - Mereka **memisahkan baju** berdasarkan kriteria itu.  
1. **Isolasi Cepat = Anomali**:  
   - Baju **normal** butuh banyak pertanyaan untuk mengisolasi.
   - Baju **sangat kotor** langsung ketahuan dalam 1-2 langkah:  
     *Contoh*:  
     - Apakah bau keringat? **Ya** akibatnya langsung terisolasi!  
1. **Voting dari Semua Teman**:  
   - Jika **8 dari 10 teman** bilang baju X gampang diisolasi, artinya baju ini adalah **baju kotor (anomali)**.

### **b. Tentang `library(solitude)`**  

Berikut adalah fitur dari `library(solitude)`:

- **Mudah Digunakan**: Hanya perlu memanggil fungsi `isolationForest$new()` dan `fit()`.  
- **Unsupervised**: Tidak membutuhkan label anomali dalam data.  
- **Cepat**: Optimized untuk dataset besar.  
- **Output**: Menghasilkan *anomaly score* (skor 0-1, semakin tinggi semakin anomali).  

Kelebihan dari _isolation forest_:

- Efisien untuk data _high-dimensional_.  
- Tidak memerlukan asumsi distribusi data.  
- Cepat karena kompleksitas waktu linear.  

Kekurangan dari _isolation forest_:

- Tidak seakurat metode _supervised_ jika label anomali tersedia.  
- _Threshold_ (`anomaly_score`) perlu diatur manual.  


Tips dan trik membuat model ini:

- **Normalisasi Data**: Pastikan fitur numerik di-_scale_ (misal: pakai `scale()`).  
- **Tuning Parameter**:  
  - `num_trees`: Semakin besar, semakin stabil (tapi lebih lambat).  
  - `sample_size`: Sesuaikan dengan ukuran dataset.  
- **Threshold**: Evaluasi dengan _business case_ (misal: ambil 5% skor tertinggi sebagai anomali).  

### **c. _Isolation Forest_ dari Data Survey**  

Sekarang kita akan buat modelnya untuk mengukur apakah responden anomali atau tidak dengan _threshold_ tertentu.

Penentuan _threshold_ bisa dilakukan melalui tiga pendekatan:

1. _Default_ (> 0.5) untuk eksplorasi awal.
1. Persentil 95% atau __mean + 2SD__ untuk analisis lebih akurat.
1. Validasi manual untuk memastikan _threshold_ sesuai kebutuhan.

Untuk kasus ini, saya akan mendefinisikan _threshold_ sebesar 90% _percentile_.

```{r}
library(solitude)

# Gabungkan fitur untuk anomaly detection
features =
  data %>%
  select(q1, q2, q3, q4, q5, waktu_jawab) %>%
  scale()  # Normalisasi

# Train Isolation Forest
model = isolationForest$new()
model$fit(features)

# Prediksi anomali
anomaly_scores = model$predict(features)

# Penentuan Batas 95%
batas = quantile(anomaly_scores$anomaly_score,.90)

anomaly_scores = 
  anomaly_scores %>% 
  mutate(is_anomaly = ifelse(anomaly_score > batas, TRUE, FALSE))  # Threshold

data$is_anomaly = anomaly_scores$is_anomaly
```

```{r}
#| echo: false

n_fraud_2 = sum(data$is_anomaly)

library(ggplot2)
ggplot(anomaly_scores, aes(x = id, y = anomaly_score, color = is_anomaly)) +
  geom_point() +
  scale_color_manual(values = c("darkgreen","red")) +
  labs(title = "Deteksi Anomali dengan Isolation Forest") +
  labs(x = "Responden ke-",
       y = "Anomaly Score",
       color = "Apakah Anomali?") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

Dari model ini, kita bisa mendapatkan ada `r n_fraud_2` orang yang terindikasi _"fraud"_.

## Perbandingan dengan Metode Statistik

```{r}
#| echo: false

tabel_temuan = 
  data %>% 
  group_by(is_fraud,is_anomaly) %>% 
  tally() %>% 
  ungroup() 

tabel_temuan %>% 
  ggplot(aes(x = is_fraud,
             y = is_anomaly,
             fill = n)) +
  geom_tile(color = "black",linewidth = 1) +
  scale_fill_gradient(low = "orange",high = "darkred") +
  geom_label(aes(label = paste0("Banyaknya responden:\n",
                                n))) +
  labs(title = "Perbandingan Metode Statstika Deskriptif vs Isolation Forest",
       x = "Metode Statistika Deskriptif",
       y = "Model Isolation Forest") +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
#| include: false

dua_tt  = tabel_temuan %>% filter(is_fraud == T) %>% filter(is_anomaly == T) %>% pull(n)

manual_ = tabel_temuan %>% filter(is_fraud == T) %>% filter(is_anomaly == F) %>% pull(n)

model_  = tabel_temuan %>% filter(is_fraud == F) %>% filter(is_anomaly == T) %>% pull(n)

```

Kita dapatkan:  

- **`r dua_tt` orang responden _fraud_** terdeteksi oleh kedua metode.  
- **`r manual_` orang responden _fraud_** terdeteksi secara manual _only_.  
- **`r model_` orang responden _fraud_** terdeteksi dari model _only_.

Mari kita lihat `r model_` orang yang terdeteksi dari model _only_:

```{r}
data %>% 
  filter(is_fraud == F) %>% filter(is_anomaly == T) %>% 
  select(id,usia,gender,q1,q2,q3,q4,q5,waktu_jawab) %>% 
  knitr::kable()
```

Dari responden ini, kita bisa dapatkan kesamaan yakni berupa waktu pengisian survey yang sama-sama singkat kecuali untuk satu responden.

## **Kesimpulan**  

- Metode statistika deskriptif sangat efektif untuk pendeteksian anomali eksplisit.  
- _Machine Learning_ (*Isolation Forest*) bisa menangkap pola yang lebih halus jika _threshold_ yang digunakan tepat.
- Perlu _oprekan_ lebih lanjut untuk bisa menggabungkan kedua metode ini.


---
  
`if you find this article helpful, support this blog by clicking the ads.`




