---
title: "Membuat Games Kata-Kata dengan Machine Learning"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(dplyr)
library(ggplot2)
```

Ceritanya pada tanggal 25 November lalu, perusahaan saya melaksanakan corporate meeting. Oleh karena pandemi, maka untuk tahun ini diadakan secara virtual saja. Tepat seminggu sebelum hari pelaksanaan, salah seorang rekan dari tim HR menghubungi saya.

> Mas Ikang nonton Netflix gak? Nonton serial Start Up gak? Kami mau bikin games seperti di serial itu.

Iya betul, saya berlangganan Netflix tapi biasanya saya pakai bukan untuk nonton serial K-drama. Hehe. Ternyata, setelah saya tonton serialnya di episode 4 menit ke 56 hingga 60an, saya mendapatkan ide bagaimana games itu akan dilakukan. Tentunya dengan twist yang disesuaikan dengan kearifan lokal perusahaan saya juga donk.

Jadi kali ini saya akan membuat machine learning model untuk membuat games kata-kata. Bagaimana caranya? Cekidot yah 

---

Hal yang disepakati di awal adalah bagaimana cara main games ini. Jadi pada hari H nanti, 300 orang peserta meeting akan diberikan sekitar 200 kata yang ditampilkan di layar. Mereka akan adu cepat menuliskan 5 kata-kata terkait 4 buah topik yang ditetapkan, yakni:

1. Agile
1. Purposeful
1. Inclusive
1. Digital transformation

Sehingga total, setiap orang akan submit 20 kata-kata (5 kata per masing-masing topik).

Dari kata-kata yang dituliskan tersebut, peserta akan mendapatkan skor (seberapa terkait kata-kata tersebut ke masing-masing topik). 40 peserta drngan skor terbaik akan menjadi pemenang.

---

Sudah kebayang kan cara mainnya? Sekarang bagaimana membuat model machine learningnya?

Pertama-tama, saya tentukan dulu kata-kata apa saja yang bisa dikaitkan dengan 4 topik di atas. Pencarian related queries yang saya lakukan di Google Ttends tidak memuaskan bagi saya. Sehingga saya harus mengambil sumber lain. Apa itu? Artikel-artikel yang ada di Harvard Business Review. Kenapa HBR? Di perusahaan saya, artikel HBR sudah biasa berseliweran di Workplace (sebutan untuk Facebook@work). Jadi saya asumsikan sebagian rekan-rekan sudah fasih membaca artikel-artikel dari HBR.

Saya mencari semua artikel terkait 4 topik itu sejak tahun 2000 hingga tanggal 23 November 2020. Saya mendapati:

- 48 links artikel terkait agile.
- 26 links artikel terkait purposeful.
- 27 links artikel terkait inclusive.
- 34 links artikel terkait digital transformation.

Tidak cuma artikel saja, rekan HR saya juga memberikan 7 jurnal (berformat `.pdf`) tentang agile, 7 jurnal tentang inclusive, dan 6 jurnal tentang purposeful.

Langkah berikutnya adalah saya harus membaca semua tulisan dari sumber-sumber tersebut untuk mendapatkan kata-kata yang akan dites. Oh maaf, bukan saya yang harus membaca yah, tapi algoritma mesinnya yang saya suruh scrape semua tulisan yang ada.

```{r,echo=FALSE}
data = data.frame(
id = c(1:8),
sumber = rep(c("link","pdf"),4),
topik = c(rep("agile",2),
          rep("inclusive",2),
          rep("purposeful",2),
          rep("digital transformation")
          ),
isi = paste0("isi artikel/jurnal ",c(1:8))
)

knitr::kable(data,caption="Contoh ilustrasi data")
```

Selanjutnya adalah tahap bebersih. Semua angka dan tanda baca selain titik saya hapus. Sengaja titik tetap saya gunakan sebagai pembeda antara satu kalimat dengan kalimat yang lain.

Setelah itu saya akan hapus semua English stopwords dan lakukan stemming dengan membuat custom function berbasis library(hunspell) di R.

Untuk menghindari kata yang terlalu banyak, untuk masing-masing topik saya hanya akan mencari 100 kata dengan frekuensi muncul terbesar.

Setelah itu, saya akan pecah baris datanya perkalimat. Sehingga saya akan dapatkan:

```{r,echo=FALSE}
data
```

Setelah itu, barulah 
