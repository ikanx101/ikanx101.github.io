---
title: "Exploratory Model Analysis: Kenapa Pemain Bola Dihargai Mahal?"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#setwd("~/Documents/ikanx101/_posts/Explainable AI/post 1")
setwd("/cloud/project/_posts/Explainable AI/post 1")
rm(list=ls())
library(dplyr)
library(caret)
library(DALEX)
load("bahan blog.rda")
```

[_Artificial intelligence_](https://ikanx101.com/blog/no-intelligence-in-AI/) (__AI__) adalah salah satu _buzzwords_ yang sedang terkenal belakangan ini.  Salah satu cabang pembahasan __AI__ yang sekarang ini cukup berkembang adalah _Responsible_ __AI__.

> Apa sih _responsible_ __AI__?

Banyak orang berkata bahwa __AI__ tidak mungkin salah alias _flawless_. Ucapan tersebut benar jika dikatakan dalam lingkup otomasi _well-defined jobs_. 

Tapi saat kita mengandalkan __AI__ untuk melakukan prediksi dan klasifikasi, ucapan tersebut harus diperhatikan dengan seksama. Saya pernah menuliskan tentang [bias yang mungkin muncul](https://ikanx101.com/blog/bias-model/) saat kita membuat atau menggunakan algoritma _machine learning_, _deep learning_, atau __AI__. 

Oleh karena itu, kita harus bisa mengeliminir bias tersebut. Apalagi bias yang bisa ditimbulkan saat kita mengikutsertakan _variables_ seperti `gender` atau `SARA` saat kita membuat algoritmanya.

## _Black Box_

Beberapa model prediksi seperti _random forest_, _XGBoost_, sampai _Artificial Neural Network_ bekerja seperti _black box_.

> Apa lagi ini maksudnya?

Saya jelaskan dengan contoh sederhana ya:

Misalkan saya memiliki `1.000` baris data dari `50` kolom _variables_. Misalkan saya ingin memprediksi sesuatu kondisi dari data tersebut dengan algoritma _Artificial Neural Network_.

Maka hal yang saya lakukan adalah `melempar` data tersebut ke dalam __ANN__ dan kita akan dapatkan _output_ hasil prediksinya.

```{r,echo=FALSE,fig.align='center'}
nomnoml::nomnoml("#direction: down,
                 [Analogi|
                    [Data|dalam bentuk matriks] -> [ANN Algorithm]
                    [ANN Algorithm] -> [Output|Desirable output]
                    [ANN Algorithm|
                      Mesin belajar sampai pintar|
                      Kitanya jadi makin pintar atau tidak?]
                    ]
                 ")
```

__ANN__ secara otomatis akan belajar dan memberikan prediksi terbaiknya kepada kita.

TAPI, jika kita bertanya-tanya:

> Mengapa hasil prediksinya seperti ini? Kenapa tidak seperti itu? Dari `50` _variables_, mana saja yang penting?

Kita tidak akan pernah bisa mendapatkan jawaban dari model tersebut.

Oleh karena itu _deep learning_ (_machine learning algorithm_ yang berbasis _Neural Network_) selalu saya katakan sebagai hal _ghaib_ yang terjadi nyata di kehidupan sehari-hari.

- Inputnya ada, yakni datanya.
- Prosesnya perhitungannya nyata tapi kita tidak bisa melihat bagaimana mesin bisa belajar.
- Outputnya ada berupa hasil prediksi. 

> TAPI kita kehilangan `why` dalam algoritma ini!

## _More Traditional Algorithm_

Jika beberapa algoritma terbaru tersebut susah untuk menjelaskan `why`-nya, kenapa kita tidak pakai algoritma __jadul__ saja?

Algoritma-algoritma __jadul__ seperti __keluarga regresi__ dan _discriminant analysis_ lebih mudah bagi kita untuk mengekplorasi sisi `why`-nya.

Tapi masalahnya algoritma __jadul__ tersebut konon kurang _reliable_ saat berhadapan dengan data berskala besar dengan struktur yang lebih aneh juga (contoh [data _images_](https://ikanx101.com/blog/deep-nutrisari/)).

Oleh karena itu, kita membutuhkan suatu _tools_ yang bisa menjelaskan sisi `why` dari algoritma kekinian seperti __ANN__.

## _Explainable AI_

Saat ini ada beberapa _libraries_ di __R__ yang bisa digunakan untuk membedah cara kerja dari algoritma. Analoginya seperti ini:

> Kalau dulu kita biasa melakukan _exploratory data analysis_, sekarang kita akan melakukan _exploratory model analysis_.

Alih-alih menganalisa datanya, kita akan fokus menganalisa modelnya (baca: algoritmanya).

Proses inilah yang disebut dengan _explainable_ __AI__ (atau _interpretable machine learning_).

_Gimana?_ Sudah cukup bingung?

Saya akan gunakan contoh sesuai dengan judul tulisan ini _yah_.

# _Problem_

## Kenapa pemain bola dihargai mahal?

Beberapa saat lalu, saya mengambil data dari __FIFA__ terkait statistik pemain dan nilai harga transfer mereka. Sejak SMA dulu, saya penasaran apa sih yang membuat seorang pemain bola dihargai mahal.

Dari sekian puluh ribu data pemain, saya hanya akan melihat pemain-pemain bola dengan kondisi:

1. Bukan GK dan pemain belakang.
1. Memiliki harga minimal `10` juta Euro.

Sehingga saya dapatkan `341` baris data pemain bola. Lalu saya hanya akan melihat `14` _variables_ berikut ini:

```{r,echo=FALSE}
colnames(data)
```

_Variables_ di atas akan saya gunakan untuk memprediksi harga pemain. Berikut adalah cuplikan data yang digunakan:

```{r,echo=FALSE}
data %>% rename(harga_dlm_juta = target) %>% head() %>% knitr::kable()
```



