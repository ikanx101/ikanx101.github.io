---
title: "Belajar Membuat Model Regresi Linear - part 1"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r,include = FALSE}
rm(list=ls())
options(digit = 3)

library(dplyr)
library(ggplot2)

x = runif(10,2,9) %>% round(1)
y = 3 * x * runif(1,0,2) + 2 * runif(1,0,3)
y = round(y,1)

data = data.frame(x,y)
```

Kita pasti sudah sering mendengar, melihat, bahkan membuat model regresi linear $y = ax + b$. Bagi saya pribadi, metode _linear curve fitting_ yang satu ini adalah salah satu metode statistik yang sering ditanyakan oleh banyak rekan kerja. Pertama kali saya mengenal regresi linear adalah pada saat kuliah _Statistika Matematika_ pada tingkat 3 dulu di S1. 

Setidaknya saya pernah menulis tiga _posts_ terkait regresi linear:

1. Bagaimana membuat model regresi linear di __R__ dan menguji asumsinya di [sini](https://ikanx101.com/blog/belajar-regresi/).
1. Aplikasi regresi linear pada perhitungan _price elasticity_ di [sini](https://ikanx101.com/blog/blog-posting-regresi/).
1. Menentukan apa yang berpengaruh terhadap kebahagiaan di suatu negara berdasarkan _World Happiness Index_ di [sini](https://ikanx101.com/blog/bahagia-survey/).

> ___Tapi belum ada sama sekali tulisan yang menjelaskan bagaimana cara menentukan nilai a dan b pada persamaan regresi linear tersebut.___

Nah, kali ini saya akan menjelaskan bagaimana cara kita menentukan nilai $a$ dan $b$ pada persamaan regresi $y = ax + b$.

---

Misalkan saya memiliki $n$ pasang data $(x_1,y_1),(x_2,y_2),..,(x_n,y_n)$ yang akan saya buat menjadi persamaan $f(x) = y = ax+b$.

Cita-cita saya adalah memiliki persamaan $f(x)$ yang __dekat__ dengan $y$ aslinya sehingga menghasilkan prediksi yang __akurat__.

Misalkan saya definisikan _error_ sebagai:

$$error = \sum_{i=1}^n d_i^2$$

di mana $d_i$ adalah __jarak__ antara hasil prediksi $x_i$ terhadap nilai _real_ $y_i$.

Saya bisa menuliskan:

$$d_i = y_i - f(x_i)$$

Kita substitusikan kembali nilai $d_i$ ke definisi _error_, sehingga:

$$error = \sum_{i=1}^n ( y_i - f(x_i) )^2$$ 

$$error = \sum_{i=1}^n ( y_i - (a x_i + b) )^2$$ 

$$error = \sum_{i=1}^n ( y_i - a x_i - b )^2$$ 

---

Ingat kembali bahwa tujuan mulia saya adalah __meminimumkan error__. Untuk itu perlu nilai $a$ dan $b$ yang tepat. Oleh karena semua data $(x_i,y_i)$ diketahui, maka kita bisa melakukan turunan parsial terhadap $a$ dan $b$ yang memenuhi:

$$\frac{\delta error}{\delta a} = 0$$

$$\frac{\delta error}{\delta b} = 0$$

Kita dapatkan:

$$\frac{\delta error}{\delta a} = -2 \sum_{i=1}^n x_i (y_i - a x_i - b) = 0$$

atau bisa ditulis sebagai: 

$$a \sum_{i=1}^n x_i^2 + b \sum_{i=1}^n x_i = \sum_{i=1}^n (x_i y_i)$$

Kita juga dapatkan:

$$\frac{\delta error}{\delta b} = -2 \sum_{i=1}^n (y_i - a x_i - b) = 0$$

atau bisa ditulis sebagai: 

$$a \sum_{i=1}^n x_i^2 + b n = \sum_{i=1}^n y_i$$

---

Nah, kedua bentuk persamaan terakhir bisa saya tuliskan dalam bentuk matriks sebagai berikut:

$$\begin{bmatrix}
n & \sum_{i=1}^n x_i \\ 
\sum_{i=1}^n x_i & \sum_{i=1}^n x_i^2 
\end{bmatrix} 
\begin{bmatrix} b \\ a \end{bmatrix} = 
\begin{bmatrix} \sum_{i=1}^n y_i \\ \sum_{i=1}^n (x_i y_i) \end{bmatrix}$$

Oleh karena $\sum_{i=1}^n x_i, \sum_{i=1}^n x_i^2, \sum_{i=1}^n (x_i y_i)$ bisa dihitung dari data, maka kita bisa tuliskan bentuk di atas menjadi bentuk $A c = d$. Jika matriks $A$ memiliki invers, artinya __nilai a dan b bisa kita hitung__.

---

Sekarang kita akan coba membuat persamaan regresi dari data tertentu berdasarkan persamaan di atas __tanpa menggunakan function__ `lm()` dari _base_-nya __R__.

Misalkan saya punya data sebagai berikut:

```{r,echo = FALSE}
x
y
```

Jika dibuat dalam bentuk _scatter plot_:

```{r,echo=FALSE}
data %>%
  ggplot(aes(x,y)) +
  geom_point() +
  theme_minimal() +
  labs(title = "Scatter plot x dan y")

sum_xi = sum(x)
sum_yi = sum(y)
sum_xi_xi = sum(x^2)
sum_xi_yi = sum(x*y)
n = length(x)
```

Untuk membuat persamaan regresinya, kita cukup hitung:

- $\sum_{i=1}^n x_i =$ `r sum_xi`
- $\sum_{i=1}^n x_i^2 =$ `r sum_xi_xi`
- $\sum_{i=1}^n (x_i y_i) =$ `r sum_xi_yi`

Lalu saya akan buat matriks berikut:

```{r,echo=FALSE}
A = matrix(c(n,sum_xi,sum_xi,sum_xi_xi),ncol = 2,byrow = T)
A
```

dan membuat _vector_ berikut:

```{r,echo=FALSE}
d = c(sum_yi,sum_xi_yi)
d
```

Untuk mencari konstantanya, saya cukup lakukan $A^{-1}d$, yakni:

```{r}
solve(A) %*% d
``` 

```{r,include=FALSE}
sol = solve(A) %*% d
```

Kita dapatkan formulanya sebagai berikut:

y = `r sol[2]` x + `r sol[1]`

Salah satu _insight_ yang bisa kita dapatkan adalah:

> ___Ternyata masalah curve fitting yang sering dimasukkan ke dalam statistika justru diselesaikan secara aljabar.___

Mari kita bandingkan nilainya dengan _base_ dari __R__ sebagai berikut:

```{r}
lm(y~x)
```

Terlihat jelas bahwa hasil antara __algoritma bikininan sendiri__ vs _base_ __R__ memiliki hasil yang serupa.

---

## _What's Next?_

Lantas apa _sih_ gunanya membuat algoritma sendiri padahal di __R__ sudah ada _function_ untuk melakukan regresi?

Hal ini akan berguna saat kita hendak __melakukan kustomisasi terhadap fungsi regresi yang kita buat__. Contohnya adalah saat kita hendak melakukan regresi linear multi peubah, regresi polinom, regresi eksponensial, dan lain sebagainya. Saya akan menjelaskannya pada _post_ berikutnya _yah_.

---

`if you find this article helpful, support this blog by clicking the ads.`
