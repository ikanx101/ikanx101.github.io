---
title: "Learning Forum: Factor Analysis part 1"
format: 
  gfm:
    html-math-method: webtex
    toc: false
    toc-depth: 4
    fig-dpi: 500
    mermaid-format: png
editor: visual
execute:
  echo: false
  warning: false
  error: false
---

# Factor Analysis

Factor analysis is a statistical technique used to understand the underlying structure of a dataset with many inter-related variables. Imagine you have a big basket of fruits, all mixed together. Factor analysis helps you sort those fruits into a smaller number of categories, like citrus fruits, berries, and stone fruits.

Here's a breakdown of the key concepts:

-   **Observed Variables:** These are the individual data points you measure, like the sweetness, size, and color of each fruit in the basket.
-   **Latent Variables (Factors):** These are underlying, unobserved characteristics that explain the relationships between the observed variables. In the fruit example, "sweetness" and "acidity" could be factors influencing how we categorize the fruits.
-   **Common Variance:** This is the variation in the observed variables that can be explained by the factors.
-   **Unique Variance:** This is the variation in each observed variable that's not explained by the factors and might be due to random errors or specific characteristics.

**The Process of Factor Analysis:**

1.  **Data Collection:** You start with a dataset containing multiple variables you suspect are influenced by some hidden factors.
2.  **Factor Extraction:** Statistical methods identify a smaller number of factors that explain most of the variation in the observed variables. There are different techniques for extraction, like Principal Component Analysis.
3.  **Factor Rotation:** This step aims to improve the interpretability of the factors. Imagine rotating the fruit basket to get a clearer view of how the fruits group based on factors.
4.  **Interpretation:** You analyze the factors and observed variables to understand the underlying meaning of the factors. In the fruit example, you might name a factor "Citrus" based on its strong correlation with sweetness and acidity.

**Benefits of Factor Analysis:**

-   **Data Reduction:** It simplifies complex datasets by identifying a smaller number of key factors.
-   **Identify Underlying Patterns:** It reveals hidden relationships between variables that might not be obvious at first glance.
-   **Model Building:** Factors can be used to create new variables or scoring systems for further analysis.

**Applications of Factor Analysis:**

-   **Psychology:** It's used to understand personality traits, intelligence, and mental health.
-   **Marketing:** It helps identify customer segments based on buying habits and preferences.
-   **Finance:** It can be used to assess financial risk or group stocks based on common factors.
-   **Social Sciences:** It can analyze survey data to uncover underlying social and economic trends.

**Things to Consider:**

-   Factor analysis assumes certain conditions about the data, so it's important to check those assumptions before applying it.
-   Interpreting factors can be subjective, so careful analysis and domain knowledge are crucial.

# Confirmatory vs Exploratory Factor Analysis

| Feature               | Confirmatory Factor Analysis (CFA)                             | Exploratory Factor Analysis (EFA)                                 |
|------------------------|------------------------|------------------------|
| **Purpose**           | Tests a pre-defined factor structure                           | Discovers the underlying factor structure                         |
| **Starting Point**    | Existing theory or hypothesis about factors                    | Large dataset with interrelated variables                         |
| **Number of Factors** | Predetermined number of factors                                | Data-driven; number of factors is explored                        |
| **Factor Loadings**   | Estimates how well each variable reflects the proposed factors | Identifies which variables group together under potential factors |
| **Interpretation**    | Focuses on confirming the hypothesized relationships           | Focuses on exploring and interpreting newly discovered factors    |
| **Flexibility**       | Less flexible; requires a strong theoretical foundation        | More flexible; allows for unexpected factor structures to emerge  |
| **Use Case**          | Validating existing scales or measurement models               | Developing new scales, understanding complex datasets             |

**Additional Points:**

-   CFA is typically used after EFA to confirm the structure identified through exploration.
-   EFA is generally considered the first step in factor analysis, while CFA is used for further validation.
-   Both methods rely on statistical tests to assess the model fit and factor loadings.

# Example: Exploring Personality Traits with EFA

Imagine you're a psychologist studying personality. You collect data from a group of students using a survey with various questions related to personality traits. Here's how EFA could be applied:

**Data:**

-   You have survey responses from 200 students on 20 different questions.
-   These questions cover aspects like:
    -   Extraversion (e.g., enjoys social gatherings, prefers talking)
    -   Neuroticism (e.g., anxious, worries easily)
    -   Agreeableness (e.g., helpful, trusts others)
    -   Conscientiousness (e.g., organized, detail-oriented)
    -   Openness to Experience (e.g., enjoys novelty, intellectual curiosity)

**EFA Steps:**

1.  **Data Preparation:** Ensure your data meets the assumptions of EFA (e.g., normality, linearity).
2.  **Factor Extraction:** You use an EFA technique like Principal Component Analysis (PCA) to identify a smaller number of factors that explain the most variance in the 20 questions.
3.  **Determining the Number of Factors:** You might use techniques like the Scree plot (a graph) to decide how many factors to retain. The Scree plot will show a clear "elbow" where the explained variance by additional factors drops off significantly.
4.  **Factor Rotation:** You might rotate the factors (like rotating the fruit basket) to improve their interpretability. This doesn't change the underlying structure but makes it easier to understand which questions relate to each factor.
5.  **Interpretation:** You analyze the questions with high loadings on each factor. Here's a possible outcome:

-   **Factor 1:** High loadings on questions related to social interaction, talkativeness, and enjoying company (Extraversion).
-   **Factor 2:** High loadings on questions about anxiety, worry, and emotional reactivity (Neuroticism).
-   **Factor 3:** High loadings on questions about helpfulness, trust, and cooperation (Agreeableness).

**Benefits:**

-   By identifying these factors, you can create a more concise personality assessment tool based on a smaller number of questions.
-   Understanding the underlying factors can shed light on how personality traits manifest in behavior.

**Limitations:**

-   EFA doesn't tell you the exact names of the factors – that requires interpretation based on your knowledge of personality psychology.
-   The results might be influenced by the specific questions chosen in the survey.

This is a simplified example, but it demonstrates how EFA can be used to explore and understand the underlying structure of complex data related to human behavior.

# Example: Validating a Customer Satisfaction Scale with CFA

Imagine you work for a company developing a new customer satisfaction survey. You've designed a scale with five questions to measure overall customer satisfaction:

-   **Question 1:** How satisfied are you with the product quality? (1 = Very Dissatisfied, 5 = Very Satisfied)
-   **Question 2:** How easy was it to use the product? (1 = Very Difficult, 5 = Very Easy)
-   **Question 3:** How helpful was customer support? (1 = Not Helpful at All, 5 = Extremely Helpful)
-   **Question 4:** How likely are you to recommend this product to others? (1 = Not Likely at All, 5 = Extremely Likely)
-   **Question 5:** Overall, how satisfied are you with your experience with our company? (1 = Very Dissatisfied, 5 = Very Satisfied)

You believe these questions all tap into a single underlying factor – "Customer Satisfaction." Here's how CFA could be applied:

**Steps:**

1.  **Hypothesized Model:** You specify a model in software like Mplus or lavaan that depicts the relationship between the five questions (observed variables) and the single latent factor (customer satisfaction).

2.  **Data Analysis:** You run the CFA analysis using data collected from a sample of your customers who completed the survey.

3.  **Evaluation of Fit:** The software provides various fit indices (e.g., Chi-square, CFI, RMSEA) to assess how well your hypothesized model (one factor) explains the data.

4.  **Interpretation:**

    -   **Good Fit:** If the fit indices suggest a good fit, it provides evidence that the five questions indeed measure a single underlying construct – customer satisfaction. The factor loadings (strength of the relationship between each question and the factor) can be examined to see how strongly each question contributes to the overall satisfaction score.
    -   **Poor Fit:** If the fit is poor, it suggests the data doesn't support your one-factor model. You might need to re-evaluate the survey or explore alternative models with multiple factors.

**Benefits:**

-   CFA provides statistical evidence to support the validity of your customer satisfaction scale.
-   Understanding factor loadings helps you refine the survey by identifying the most relevant questions.

**Limitations:**

-   CFA relies on strong theoretical justification for the hypothesized model.
-   Poor fit indices might not always be due to a faulty model; data quality issues could also contribute.

This example showcases how CFA can be used to confirm the structure of a measurement tool and ensure it accurately reflects the underlying concept you're trying to assess.

## Goodness-of-Fit Indices in Confirmatory Factor Analysis (CFA)

Here's a table summarizing common goodness-of-fit indices used in CFA:

| Index                                           | Description                                                                                                     | Recommended Value                                                                    | Interpretation                                                                                                                  |
|------------------|------------------|------------------|------------------|
| Chi-square (χ²)                                 | Absolute measure of model fit based on the difference between observed and model-predicted covariance matrices. | Not a definitive measure on its own; sensitive to sample size. A lower χ² is better. | Use in conjunction with other indices; non-significant χ² suggests good fit, but significance doesn't necessarily mean bad fit. |
| Goodness-of-Fit Index (GFI)                     | Proportion of variance explained by the model.                                                                  | \> .90                                                                               | Higher values indicate better fit.                                                                                              |
| Adjusted Goodness-of-Fit Index (AGFI)           | Adjusts GFI for model complexity (number of parameters).                                                        | \> .85                                                                               | Higher values indicate better fit, especially for complex models.                                                               |
| Normed Fit Index (NFI)                          | Compares the fit of the hypothesized model to a null model with no relationships.                               | \> .90                                                                               | Higher values indicate better fit.                                                                                              |
| Comparative Fit Index (CFI)                     | Compares the fit of the hypothesized model to a baseline model with no latent variables.                        | \> .95                                                                               | Higher values indicate better fit.                                                                                              |
| Root Mean Square Error of Approximation (RMSEA) | Estimate of average error of approximation per degree of freedom.                                               | \< .08 (good), .08-.10 (acceptable)                                                  | Lower values indicate better fit.                                                                                               |

**Important Notes:**

-   There are no strict cutoffs for all indices, and researchers often consider a combination of multiple indices to evaluate model fit.
-   The recommended values might vary slightly depending on the specific software and reference source.
-   Other fit indices also exist, but these are some of the most commonly used.

By examining these indices, you can assess how well your hypothesized factor structure aligns with the actual data in your CFA analysis.
