---
title: "Beberapa Analisa Lain yang Bisa Diaplikasikan pada Geo Marketing"
format:
  gfm:
    html-math-method: webtex
fig-dpi: 500
fig-width: 8
fig-height: 4.5
editor: source
execute:
  warning: false
  echo: false
error: false
---

```{r}
#| include: false

setwd("~/ikanx101.github.io/_posts/geo marketing/post_9")

rm(list=ls())
gc()

library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr)
library(ggmap)
library(janitor)
```

Beberapa minggu belakangan, beberapa departemen meminta kepada saya untuk melakukan *web scraping* beberapa kategori *point of interest* dari **Google Maps** dan **Google Places**. Tujuan mereka sederhana, yakni:

> Menentukan area atau POI mana yang harus digarap pada tahun ini. Syukur-syukur penggarapan ini akan meningkatkan omset perusahaan.

Setelah saya *scrape* dan berikan data kepada mereka, artinya **sudah menjadi kewajiban mereka** untuk menentukan area dan POI mana yang harus digarap. Lantas bagaimana caranya? *Jujurly*, saya kurang mengetahui hal tersebut tapi saya yakin mereka sudah punya pakem tersendiri.

------------------------------------------------------------------------

Sampai saat ini, saya sudah menuliskan [12 *posts* di blog saya ini terkait *geo marketing*](https://ikanx101.com/tags/#geomarketing). Jika saya hendak membantu rekan-rekan di kantor untuk **menentukan area dan POI yang hendak digarap**, apakah bisa digunakan cara seperti yang pernah saya tulis dari salah satu dari 12 *posts* tersebut? **Jawabannya *TENTU BISA!***.

> Saya pernah menuliskan beberapa analisa di *geo marketing* yang bisa jadi basis pengambilan keputusan tersebut.

*Nah*, pada *post* kali ini saya akan melakukan beberapa alternatif analisa lain yang belum pernah saya lakukan sebelumnya pada topik *geo marketing*. Beberapa analisa ini sebenarnya sudah pernah saya lakukan di topik lainnya tapi ternyata *works well* juga di *geo marketing*.

**Rekan-rekan bisa melihat setiap analisa yang kelak saya tuliskan di bawah sebagai analisa-analisa yang terpisah** sehingga tidak ada kewajiban untuk disangkutpautkan sama sekali antar hasilnya.

Sebagai contoh, saya akan melakukan analisa untuk POI berupa **tempat makan kategori tertentu** di Kota Surabaya, tepatnya di Kecamatan Gubeng dan Genteng.

```{r}
load("analisa_1.rda")

key = "AIzaSyBlZpsnqIhuJDHZ-nGo1VrU3PmKDW18-ls"

register_google(key = key)

lisbon_satellite <- get_map("Kota Surabaya",
                            source = "google",
                            api_key = api_secret,zoom=13)

basis =
  df_sel %>%
  select(lat,long) %>%
  distinct()

ggmap(lisbon_satellite) +
  geom_point(data = basis,aes(x = long,y = lat),
             size = .9,
             color = "steelblue") +
  theme_void() +
  coord_equal()

```

Apa saja analisanya? *Cekidot!*

## Alternatif Analisa I: Kuadran *Rating* vs *User*

Analisa pertama yang hendak saya lakukan sebenarnya sangat sederhana, yakni cukup dengan membuat *scatter plot* antara *rating* dan berapa banyak *user* yang memberikan *rating*. Tujuannya adalah memetakan tempat makan mana yang termasuk ke dalam kuadran-kuadran sebagai berikut:

|                   | Review sedikit         | Review Banyak        |
|-------------------|------------------------|----------------------|
| **Rating tinggi** | *The Hidden gems*      | *The Populars*       |
| **Rating rendah** | *The Under performers* | *The Public critics* |

Dari peta ini, tentu strategi yang dijalankan per masing-masing kuadran akan berbeda. Mari kita lihat plot pertama sebagai berikut ini:

```{r}
p1
```

Kita bisa melihat bahwa kuadran yang dihasilkan secara visual sangat *mepet* dan tidak tersebar secara proporsional. Hal ini terjadi karena *range* dari data banyaknya *user* yang memberikan *rating* sangat jauh besar dan *skewed* ke salah satu sisi. Oleh karena itu, saya bisa melakukan transformasi dengan menggunakan fungsi logaritmik. Berikut adalah grafik kedua:

```{r}
p2
```

Setelah ditransformasi, sumbu *x* sudah relatif menyebar rata **tapi** data pada *rating* yang masih *skewed*. Jika dibuat kuadran, maka bentuknya seperti ini:

```{r}
p3
```

```{r}
df_sel %>% 
  tabyl(kuadran) %>% 
  adorn_pct_formatting() %>% 
  adorn_totals() %>% 
  knitr::kable()
```

Dari analisa ini, tim terkait bisa memilih kuadran tertentu sebagai target POI yang hendak diajak kerja sama.

**TAPI menurut keyakinan saya**, untuk data dengan rentang yang terlalu mepet atau terlalu lebar dan tergambarkan sebagai *skewed distribution*, alternatif analisa ini bisa menimbulkan bias dan kurang tepat untuk digunakan.

## Alternatif Analisa II: *Spatial Clustering \>\< K-Means Clustering*

Pada analisa ini, saya akan melakukan [dua teknik *clustering* yang berbeda](https://ikanx101.com/blog/clustering-R/), yakni:

1.  DBscan untuk mengelompokkan tempat-tempat makan yang berdekatan di suatu area berdasarkan data *longlat*-nya.
2.  K-Means untuk mengelompokkan tempat-tempat makan berdasarkan *rating* dan berapa banyak *user* yang memberikan rating.

Tujuannya adalah menjawab pertanyaan berikut ini:

1.  Apakah tempat-tempat makan dengan *rating* tinggi cenderung berkumpul di area elit tertentu?
2.  Apakah ada pusat kuliner baru yang terbentuk secara organik?

Berikut adalah *summary* hasilnya:

![](dashboard_clustering.png){width="550"}

```{r}
rm(list=ls())
load("analisa_2.rda")
```

1.  Ada 13 *clusters* spasial plus 1 *noise cluster* spasial.
2.  Ada empat *clusters* berdasarkan *rating* dan berapa banyak *user* yang memberikan *rating*. *Cluster* ***The Viral Venues*** dan ***The Exclusive*** akan menjadi poin penting untuk menentukan area spasial kelak.

```{r}
kmeans_summary <- df_sel %>%
  group_by(kmeans_cluster_label) %>%
  summarise(
    n_restoran = n(),
    avg_rating = mean(rating, na.rm = TRUE),
    avg_user_rating = mean(user_rating, na.rm = TRUE),
    median_rating = median(rating, na.rm = TRUE),
    median_user_rating = median(user_rating, na.rm = TRUE),
    prop_high_rating = sum(rating >= 4.5) / n(),
    prop_popular = sum(user_rating >= 100) / n()
  )

kmeans_summary %>% knitr::kable()
```

Sekarang kita akan menjawab kedua pertanyaan yang ada dari grafik dan perhitungan yang sudah saya lakukan.

**Apakah restoran dengan *rating* tinggi cenderung berkumpul di area elit tertentu?**

Perhatikan grafik berikut ini:

![](plot_5.png){width="550"}

Plot ini adalah gabungan dari analisa *clustering spatial* dengan *clustering* berdasarkan *rating* dan *user*. Jika tempat-tempat makan yang termasuk ke dalam *the Viral Venues* dan *the Exclusive* terkonsentrasi di area spasial tertentu, itu mengindikasikan suatu area termasuk ke dalam elit. Untuk menentukannya, saya akan membuat skor dengan membobotkan proporsi jenis tempat makan yang ada.

Bobot tertinggi untuk tempat makan *the Viral Venues*, kemudian *the Exclusive*, lalu *the Trusted*. Sebagai contoh, bobot yang saya gunakan **tergantung dari keyakinan saya *ya***.

```{r}
df_skor = 
  df_sel %>% 
  tabyl(dbscan_cluster,kmeans_cluster_label) %>% 
  adorn_percentages("row") %>% 
  mutate(skor = 2 * `The Viral Venues` + `The Exclusive` + .5 * `The Trusted`) %>% 
  arrange(desc(skor)) %>% 
  select(dbscan_cluster,skor) %>% 
  mutate(skor = skor * 100,
         skor = round(skor,2)) 

df_sel %>% 
  tabyl(dbscan_cluster,kmeans_cluster_label) %>% 
  adorn_percentages("row") %>%
  adorn_totals("col") %>% 
  adorn_pct_formatting() %>% 
  merge(df_skor) %>% 
  arrange(desc(skor)) %>% knitr::kable()
```

Saya dapatkan *cluster spasial* ke 5 dan 9 memiliki skor tertinggi, yakni mereka yang berada pada:

```{r}
key = "AIzaSyBlZpsnqIhuJDHZ-nGo1VrU3PmKDW18-ls"

register_google(key = key)

lisbon_satellite <- get_map("Tunjungan Plaza, Kota Surabaya",
                            source = "google",
                            api_key = api_secret,zoom=15)

basis =
  df_sel %>%
  filter(dbscan_cluster %in% c(9,5)) %>% 
  select(lat,long,dbscan_cluster) %>%
  distinct()

ggmap(lisbon_satellite) +
  geom_point(data = basis,aes(x = long,y = lat,color = dbscan_cluster),
             size = 1.2) +
  scale_color_manual(values = c("blue","green")) +
  theme_void() +
  coord_equal() +
  labs(color = "Cluster Spasial ke-")
```

**Apakah ada pusat kuliner baru yang terbentuk secara organik?**

Saya akan membuat definisi **tempat makan baru** berdasarkan banyak *user* yang memberikan *rating*. Jika "sedikit", maka saya asumsikan tempat makan tersebut merupakan tempat makan baru. Berikut ini adalah *cluster* spasial yang memiliki tempat-tempat makan baru terbanyak di antara *clusters* yang lain:

```{r}
cluster_baru = 
  df_sel %>% 
  mutate(baru = ifelse(user_rating < 30,T,F)) %>% 
  group_by(dbscan_cluster) %>% 
  summarise(new = sum(baru) / length(baru)) %>% 
  ungroup() %>% 
  arrange(desc(new)) %>% 
  head(3) %>% pull(dbscan_cluster)
  

lisbon_satellite <- get_map("Universitas Airlangga Kampus B, Kota Surabaya",
                            source = "google",
                            api_key = api_secret,zoom=14)

basis =
  df_sel %>%
  filter(dbscan_cluster %in% cluster_baru) %>% 
  select(lat,long,dbscan_cluster) %>%
  distinct()

ggmap(lisbon_satellite) +
  geom_point(data = basis,aes(x = long,y = lat,color = dbscan_cluster),
             size = 1.2) +
  scale_color_manual(values = c("blue","green","purple")) +
  theme_void() +
  coord_equal() +
  labs(color = "Cluster Spasial ke-")

```

Dari analisa alternatif ini, saya bisa mendapatkan beberapa area yang bisa digarap dengan definisi yang sudah saya tentukan. Tentunya definisi ini bisa disesuaikan dengan kebutuhan yang diperlukan (jika mau).

## Alternatif Analisa III: Koreksi *Bayesian Rating*

**Menurut keyakinan saya**, jika ada dua tempat makan yang:

1.  Punya *rating* 5 dari penilaian 50 orang *user*.
2.  Punya *rating* 5 dari penilaian 1.000 orang *user*.

**punya derajat (atau *rating*) yang berbeda**. Lebih banyak *user* yang memberikan *rating* membuat derajat kepercayaan atas penilaian lebih tinggi. Lantas agar *rating* yang digunakan *fair enough*, apa yang harus saya lakukan? Saya akan melakukan perhitungan *Bayesian Rating Correction* untuk mendapatkan estimasi *rating* yang lebih *fair* memanfaatkan informasi *prior* berupa rata-rata *rating* tempat makan populasi data saya.

> Konsep *Bayesian Rating* adalah menggabungkan informasi dari *rating* individu dengan *prior* untuk mendapatkan *rating* yang lebih akurat. Saya pernah menuliskan [beberapa topik terkait analisa Bayesian](https://ikanx101.com/tags/#bayesian) di *blog* saya.

Untuk melakukan koreksi ini, saya hanya akan memilih tempat makan yang memiliki *rating* dengan banyaknya *user* lebih dari 30 orang. Kenapa? Karena jika terlalu kecil, koreksi yang dihasilkan punya *error* lebih tinggi.

![](bayesian_rating_analysis.png){width="550"}

Dari 242 tempat makan yang saya proses, saya mendapatkan *mean rating original* sebesar **4.479959**. Setelah dikoreksi, *mean rating Bayesian*-nya menjadi **4.480827**. Terlihat tidak ada perubahan yang signifikan dari nilai *mean*-nya namun sebaran data hasil koreksi menjadi lebih *compact* di mana standar deviasinya berubah dari *original* **0.2469339** menjadi *Bayesian* **0.12283**.

Ada satu hal yang perlu saya sampaikan juga: **tempat makan dengan *user* yang lebih banyak memberikan hasil *confidence* pengoreksian yang lebih tinggi juga**. Maka dari itu, saya coba kategorikan tiap tempat makan menjadi kelompok:

1.  *Confidence* koreksi **sangat rendah**, tempat makan dengan *user* 30 - 50 orang.
2.  *Confidence* koreksi **rendah**, tempat makan dengan *user* 50 - 100 orang.
3.  *Confidence* koreksi **sedang**, tempat makan dengan *user* 100 - 150 orang.
4.  *Confidence* koreksi **tinggi**, tempat makan dengan *user* 150 - 200 orang.
5.  *Confidence* koreksi **sangat tinggi**, tempat makan dengan *user* di atas 200 orang.

Grafik di atas menampilkan perubahan *rating* signifikan (baik meningkat atau turun) yang dialami oleh beberapa tempat makan. Sedangkan tabel berikut ini adalah **top 10** tempat-tempat makan yang memiliki *rating* tertinggi hasil koreksi:

```{r}
rm(list=ls())

df = read.csv("restaurant_ratings_bayesian_corrected.csv") %>% janitor::clean_names()

df %>% 
  arrange(desc(bayesian_rating)) %>% 
  head(10) %>% 
  select(nama,original_rating,bayesian_rating,user_count,confidence_category) %>% 
  knitr::kable()
```

## Alternatif Analisa IV: Analisis Hubungan Jarak dan Kualitas (*Spatial Correlation*)

Tujuan dari analisa ini adalah:

1.  Apakah tempat-tempat makan yang letaknya **berdekatan** cenderung memiliki *rating* yang mirip?
2.  Apakah kualitas tempat makan menular ke sebelahnya?

Untuk analisa ini, saya menggunakan [perhitungan jarak *real* dari *Openstreetmaps* pada mode **berjalan kaki**](https://ikanx101.com/blog/osrm-R/). Kemudian dua tempat makan disebut **berdekatan** jika jaraknya maksimum 50 meter berjalan kaki. Perlu saya akui bahwa proses membentuk matriks jarak antar tempat makan menggunakan *Openstreetmaps* membutuhkan waktu yang sangat amat lama.

Dari hampir enam ratus data tempat makan yang ada, saya mendapatkan xx pasang tempat makan yang masuk ke dalam definisi **berdekatan**. Jika saya hitung korelasi rating antar kedua tempat makan yang berdekatan, saya dapatkan:


```
Restoran yang Berdekatan (<50 m):

  - Jumlah pasangan: 274
  - Korelasi rating = -0.003
  - Rata-rata selisih rating: 0.491
```

```{r}
rm(list=ls())

load("analisa_4.rda")

p4
```

Ternyata __tidak ada korelasi__ antara _rating_ dari dua tempat makan berdekatan yang berjarak maksimum 50 meter.

Hasil __Moran Test__ juga menunjukkan tidak ada pola spasial yang signifikan dalam distribusi _rating_.

Jadi kedua pertanyaan bisnis di atas bisa kita jawab dengan tegas bahwa __kualitas restoran tidak dipengaruhi oleh lokasi tetangga__.

## Alternatif Analisa V: Analisis Anomali

Tujuan dari analisa ini adalah mencari tempat makan yang **melawan arus** di wilayahnya.

Saya mendefinisikan radius pencarian __"tetangga"__ dari suatu tempat makan sebesar 400 meter dan satu _neighborhood_ harus berisi minimal 20 tempat makan. Kemudian saya definisikan juga __tempat makan disebut dengan anomali saat *rating*-nya memiliki perbedaan rating minimal 0.8 dari _rating_ rata-rata di _neighborhood_ tersebut__.

Berdasarkan definisi tersebut, saya mendapatkan ada __tujuh tempat makan__ yang __melawan arus__. Berikut adalah grafik yang menandakan perbedaan _rating_ ketujuh tempat makan tersebut dengan _rating_ rata-rata di _neighborhood_-nya:

```{r}
rm(list=ls())
load("analisa_5.rda")

p2
```

Berikut adalah _heatmap_ berdasarkan longlat dan rata-rata _rating_ wilayah:

```{r}
p4

```

Dari analisa ini, kita bisa mengubah asumsi-asumsi yang saya gunakan tadi untuk mendapatkan tempat makan yang __melawan arus__.

# _EPILOG_

Dari lima alternatif analisa yang saya tuliskan di atas, kita bisa memilih satu atau lebih analisa dengan tujuan yang tentunya berbeda-beda tergantung kebutuhan. Perlu saya ingatkan kembali bahwa analisa ini murni berdasarkan data terbatas seperti longlat, _rating_, dan banyaknya _user_ yang memberikan _rating_. Sedangkan pada kondisi _real_, ada banyak data yang tak tergambarkan dari analisa ini.

